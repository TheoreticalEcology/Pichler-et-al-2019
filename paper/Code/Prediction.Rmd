---
# title: "PredictionSimulation"
# author: "Max Pichler"
# date: "26 August 2018"
documentclass: report
fontsize: 11pt
output:
  pdf_document: 
    highlight: monochrome
  html_document: 
    keep_md: yes
    
    
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE,warning = FALSE, error = F,tidy.opts=list(width.cutoff=40),tidy=TRUE , tidy = TRUE,size = "tiny")
hook_output = knitr::knit_hooks$get('output')
knitr::knit_hooks$set(output = function(x, options) {
  if (!is.null(n<- options$linewidth)) {
    x = knitr:::split_lines(x)
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})
```
# Simulation

## Run Simulation for comparing predictive performance
```{r, results = FALSE}
library(TraitMatching)
library(mlr)
oldpar = par()
reset = function() suppressWarnings(do.call(par, oldpar))
run =TRUE
set.seed(42)
```



```{r, echo=FALSE}
df = data.frame("Trait Interaction" = c("A1 + B2", "A2 + B3", "A3 + B4"), 
                "Type" = c("discrete + continuous", "continuous + continuous", "continuous + continuous"),
                "Weight" = c(1,1,3))
knitr::kable(df,caption = "Simulated trait combinations")
```

## meta parameter
```{r}
epochs = 50L
iter = 30
parallel = 30L
run = TRUE
crossValidation = list(outer = list(method = "SpCV", iters = 5, predict = "both"), 
                                 inner = list(method = "SpCV", iters = 3))


run = TRUE
```

### Without effects and abundances - baseline
- wide and weak effects (gaussian with sd = 100)
- no species abundances
- 50*100 base network size
```{r,results=FALSE}
set.seed(42)
simulatedData = simulateInteraction(main = NULL, inter = matrix(c("A1", "B1"), ncol = 2, byrow = T),
                              weights = list(inter = 1),
                              NumberA = 50, NumberB = 100, traitsA = c(0,6), 
                              traitsB = c(0,6),abundance = FALSE, specRange = c(100,100))
table(as.matrix(minOneInter(simulatedData$binar(3e2))))
```

```{r, results=FALSE}
resultBaselineC = runTM(createCommunity(simulatedData$A, simulatedData$B, minOneInter(simulatedData$binar(3e2))), 
                         method = c("dnn", "cnn", "knn", "naive", "RFranger", "boost", "glm"), 
          settings = list(dnn = list(seed = 42,  activation = "relu", drop = 0.2, archFunction = "continous", epochs = epochs),
                          cnn = list(seed = 42, activation = "relu", 
                                     drop = 0.2, nConv = 1, archFunction = "continous", epochs = epochs)),
                       tune = "random", iters = iter,  fitSpecies = F,
                       crossValidation = crossValidation, 
                       balanceClasses = "None", block = T, parallel = parallel, seed = 42, keepModels = T)
    saveRDS(resultBaselineC, file = "./Results/simBaselineC.RDS")

resultBaselineR = runTM(createCommunity(simulatedData$A, simulatedData$B, minOneInter(simulatedData$poisson(3e2)),log = FALSE ), 
                         method = c("negBinDnn", "RFranger", "knn", "boost", "glm"), 
          settings = list(negBin = list(seed = 42, batch = 50, 
                                        distribution = "poisson",  archFunction = "continous", epochs = epochs),
                          boost = list( objective = "count:poisson"),
                          glm = list(family = "poisson")),
                       tune = "random", iters = iter,  fitSpecies = F,
                       crossValidation = crossValidation, tuningMetric = "spearmanrho",
                       balanceClasses = "None", block = T, parallel = parallel, seed = 42, keepModels = T)
    saveRDS(resultBaselineR, file = "./Results/simBaselineR.RDS")
```

### Without effects but with abundances - baseline with abundances
- wide and weak effects (gaussian with sd = 100)
- species abundances
- 50*100 base network size
```{r,results=FALSE}
set.seed(42)
simulatedData = simulateInteraction(main = NULL, inter = matrix(c("A1", "B1"), ncol = 2, byrow = T),
                              weights = list(inter = 1),
                              NumberA = 50, NumberB = 100, traitsA = c(0,6), 
                              traitsB = c(0,6),abundance = function(a,b) return(rexp(a, 2)), specRange = c(100,100))
table(as.matrix(minOneInter(simulatedData$binar(4e3))))
```
```{r, results=FALSE}
resultAbC = runTM(createCommunity(simulatedData$A, simulatedData$B, minOneInter(simulatedData$binar(4e3))), 
                         method = c("dnn", "cnn", "knn", "naive", "RFranger", "boost", "glm"), 
          settings = list(dnn = list(seed = 42,  activation = "relu", drop = 0.2, archFunction = "continous", epochs = epochs),
                          cnn = list(seed = 42, activation = "relu", 
                                     drop = 0.2, nConv = 1, archFunction = "continous", epochs = epochs)),
                       tune = "random", iters = iter,  fitSpecies = F,
                       crossValidation = crossValidation, 
                       balanceClasses = "None", block = T, parallel = parallel, seed = 42, keepModels = T)
    saveRDS(resultAbC, file = "./Results/simAbC.RDS")
    
resultAbR = runTM(createCommunity(simulatedData$A, simulatedData$B, minOneInter(simulatedData$poisson(4e3)),log = FALSE), 
                         method = c("negBinDnn", "RFranger", "knn", "boost", "glm"), 
          settings = list(negBin = list(seed = 42,  batch = 50, 
                                        distribution = "poisson",  archFunction = "continous", epochs = epochs),
                          boost = list( objective = "count:poisson"),
                          glm = list(family = "poisson")),
                       tune = "random", iters = iter,  fitSpecies = F,
                       crossValidation = crossValidation, tuningMetric = "spearmanrho",
                       balanceClasses = "None", block = T, parallel = parallel, seed = 42, keepModels = T)
    saveRDS(resultAbR, file = "./Results/simAbR.RDS")
```

### With effects and w/o abundances - Network Sizes
- with strong effects (gaussian with small sd and high interaction weight)
- without species abundances 
- varying network sizes

Create Simulation:
```{r,results=FALSE}
set.seed(42)
simulatedData = simulateInteraction( main = NULL, inter = matrix(c("A1", "B1",
                                                                   "A2", "B2",
                                                                   "A3", "B3"), ncol = 2, byrow = T),
                              weights = list(inter = c(10,10,10)),
                              NumberA = 100, NumberB = 200, traitsA = c(0,6), 
                              traitsB = c(0,6),abundance = FALSE, specRange = c(0.5,1.2))
table(as.matrix(minOneInter(simulatedData$binar(1.2e-1))))
```

We tested the influence of three sizes on the performance. We set the observation time $=4e3$ to get for alomost all species at least one interaction. We sampled 25 \%, 50 \% and 100 \% of the species to get three network sizes of:

```{r,results=FALSE}
interBaseP = minOneInter(simulatedData$poisson(1.2e-1))
interBaseC = minOneInter(simulatedData$binar(1.2e-1))
smallP = interBaseP[sample(rownames(interBaseP), 0.25*length(rownames(interBaseP))),
                    sample(colnames(interBaseP), 0.25*length(colnames(interBaseP)))]
smallC = interBaseC[rownames(smallP), colnames(smallP)]

midP = interBaseP[sample(rownames(interBaseP), 0.5*length(rownames(interBaseP))),
                  sample(colnames(interBaseP), 0.5*length(colnames(interBaseP)))]
midC = interBaseC[rownames(midP), colnames(midP)]

largeP = interBaseP
largeC = interBaseC

sizeC = list(smallC = smallC, midC = midC, largeC = largeC)
sizeR = list(smallP = smallP, midP = midP, largeP = largeP)


```


Fit models with 30 random tuning steps, nested cross-validation (five-fold outer and three-fold inner). SpcCV = Leave out species with all of their interactions. AUC and Spearman evaluated tuning.
```{r,results=FALSE}
resultC = list()
if(run){
  resultC = list()
  for(i in 1:length(sizeC)){
    resultC[[i]] = runTM(createCommunity(simulatedData$A, simulatedData$B, sizeC[[i]]), 
                         method = c("dnn", "cnn", "knn", "naive", "RFranger", "boost", "glm"), 
          settings = list(dnn = list(seed = 42,  activation = "relu", drop = 0.2, archFunction = "continous", epochs = epochs),
                          cnn = list(seed = 42, activation = "relu", 
                                     drop = 0.2, nConv = 1, archFunction = "continous", epochs = epochs)),
                       tune = "random", iters = iter,  fitSpecies = F,
                       crossValidation = crossValidation, 
                       balanceClasses = "None", block = T, parallel = parallel, seed = 42, keepModels = T)
    saveRDS(resultC, file = "./Results/simSizeC.RDS")
  }
  
  
  resultR = list()
  for(i in 1:length(sizeC)){
    resultR[[i]] = runTM(createCommunity(simulatedData$A, simulatedData$B, sizeR[[i]], log = F), 
                         method = c("negBinDnn", "RFranger", "knn", "boost", "glm"), 
          settings = list(negBin = list(seed = 42,  batch = 50, 
                                        distribution = "poisson",  archFunction = "continous", epochs = epochs),
                          boost = list( objective = "count:poisson"),
                          glm = list(family = "poisson")),
                       tune = "random", iters = iter,  fitSpecies = F,tuningMetric = "spearmanrho",
          crossValidation = crossValidation,
                        block = T, parallel = parallel, seed = 42, keepModels = T)
    
    saveRDS(resultR, file = "./Results/simSizeR.RDS")
  }
}

```

### With effects and w/o abundances - Observation time
Varying observation times results in diffrent class distributions (classification). I choose times so, that the positive interaction had class proportions of 10 \%, 25 \% and 50 \%:

```{r,results=FALSE}
set.seed(42)
simulatedData = simulateInteraction( main = NULL, inter = matrix(c("A1", "B1",
                                                                   "A2", "B2",
                                                                   "A3", "B3"), ncol = 2, byrow = T),
                              weights = list(inter = c(10,10,10)),
                              NumberA = 100, NumberB = 200, traitsA = c(0,6), 
                              traitsB = c(0,6),abundance = FALSE, specRange = c(0.5,1.2))
table(as.matrix(minOneInter(simulatedData$binar(1.2e-1))))

obsC = list(low = minOneInter(simulatedData$binar(0.7e-2)), 
            mid = minOneInter(simulatedData$binar(3.2e-2)), 
            high = minOneInter(simulatedData$binar(1.2e-1)))

obsR = list(low = minOneInter(simulatedData$poisson(0.7e-2)), 
            mid = minOneInter(simulatedData$poisson(3.2e-2)), 
            high = minOneInter(simulatedData$poisson(1.2e-1)))
```


Fit models with 30 random tuning steps, nested cross-validation (five-fold outer and three-fold inner). SpcCV = Leave out species with all of their interactions. AUC and Spearman evaluated tuning.
```{r,results=FALSE}
if(run){
resultC = list()
  for(i in 1:length(obsC)){
    if(i != 3) bc = "Over"
    else bc = "None"
    resultC[[i]] = runTM(createCommunity(simulatedData$A, simulatedData$B, obsC[[i]]), 
                         method = c("dnn", "cnn", "knn",  "naive", "RFranger", "boost", "glm"), 
          settings = list(dnn = list(seed = 42,  activation = "relu",  archFunction = "continous",  epochs = epochs),
                          cnn = list(seed = 42,  activation = "relu", 
                                     drop = 0.2, nConv = 1, archFunction = "continous", epochs = epochs)),
                       tune = "random", iters = iter,  fitSpecies = F,
                       crossValidation = crossValidation, 
                       balanceClasses = bc, block = T, parallel = parallel, seed = 42, keepModels = T)
    saveRDS(resultC, file = "./Results/simObsC.RDS")
  }
  
  resultR = list()
  for(i in 1:length(obsR)){
      resultR[[i]] = runTM(createCommunity(simulatedData$A, simulatedData$B, obsR[[i]], log = F), 
                           method = c("negBinDnn", "RFranger",  "knn", "boost", "glm"), 
          settings = list(negBin = list(seed = 42,  batch = 50, 
                                        distribution = "poisson",  archFunction = "continous", epochs = epochs),
                          boost = list( objective = "count:poisson"), 
                          glm = list(family = "poisson")),
                       tune = "random", iters = iter,  fitSpecies = F,tuningMetric = "spearmanrho",
          crossValidation = crossValidation,
                        block = T, parallel = parallel, seed = 42, keepModels = T)
    
    saveRDS(resultR, file = "./Results/simObsR.RDS")
  }
}
```





##  Results
```{r, echo = FALSE,results=FALSE}
if(run){
  ResultSizeC = readRDS(file = "./Results/simSizeC.RDS")
  ResultSizeR = readRDS(file = "./Results/simSizeR.RDS")
  
  ResultObsC = readRDS(file = "./Results/simObsC.RDS")
  ResultObsR = readRDS(file = "./Results/simObsR.RDS")
  
  ResultAbC = readRDS(file = "./Results/simAbC.RDS")
  ResultAbR = readRDS(file = "./Results/simAbR.RDS")
  
  ResultBaselineC = readRDS(file = "./Results/simBaselineC.RDS")
  ResultBaselineR = readRDS(file = "./Results/simBaselineR.RDS")
  
  ResultSizeC_SVM = readRDS(file = "./Results/simSizeC_SVM.RDS")
  ResultSizeR_SVM = readRDS(file = "./Results/simSizeR_SVM.RDS")
  
  ResultObsC_SVM = readRDS(file = "./Results/simObsC_SVM.RDS")
  ResultObsR_SVM = readRDS(file = "./Results/simObsR_SVM.RDS")
  
  ResultAbC_SVM = readRDS(file = "./Results/simAbC_SVM.RDS")
  ResultAbR_SVM = readRDS(file = "./Results/simAbR_SVM.RDS")
  
  ResultBaselineC_SVM = readRDS(file = "./Results/simBaselineC_SVM.RDS")
  ResultBaselineR_SVM = readRDS(file = "./Results/simBaselineR_SVM.RDS")
    
  ResultSizeC_GLM = readRDS(file = "./Results/simSizeC_GLM.RDS")
  ResultSizeR_GLM = readRDS(file = "./Results/simSizeR_GLM.RDS")
  
  ResultObsC_GLM = readRDS(file = "./Results/simObsC_GLM.RDS")
  ResultObsR_GLM = readRDS(file = "./Results/simObsR_GLM.RDS")
  
  ResultAbC_GLM = readRDS(file = "./Results/simAbC_GLM.RDS")
  ResultAbR_GLM = readRDS(file = "./Results/simAbR_GLM.RDS")
  
  ResultBaselineC_GLM = readRDS(file = "./Results/simBaselineC_GLM.RDS")
  ResultBaselineR_GLM = readRDS(file = "./Results/simBaselineR_GLM.RDS")
  source("./Code/helpFunctions.R")
  
  for(i in 1:3){
    ResultSizeC[[i]]$Result[["SVM"]] = ResultSizeC_SVM[[i]]$Result$SVM
    ResultSizeR[[i]]$Result[["SVM"]] = ResultSizeR_SVM[[i]]$Result$SVM
    
    ResultObsC[[i]]$Result[["SVM"]] = ResultObsC_SVM[[i]]$Result$SVM
    ResultObsR[[i]]$Result[["SVM"]] = ResultObsR_SVM[[i]]$Result$SVM
    
    ResultSizeC[[i]]$Result[["glm"]] = ResultSizeC_GLM[[i]]$Result$glm
    ResultSizeR[[i]]$Result[["glm"]] = ResultSizeR_GLM[[i]]$Result$glm
    
    ResultObsC[[i]]$Result[["glm"]] = ResultObsC_GLM[[i]]$Result$glm
    ResultObsR[[i]]$Result[["glm"]] = ResultObsR_GLM[[i]]$Result$glm
    
    ResultSizeC[[i]]$Result[["glm_step"]] = ResultSizeC_GLM[[i]]$Result$glm_step
    ResultSizeR[[i]]$Result[["glm_step"]] = ResultSizeR_GLM[[i]]$Result$glm_step
    
    ResultObsC[[i]]$Result[["glm_step"]] = ResultObsC_GLM[[i]]$Result$glm_step
    ResultObsR[[i]]$Result[["glm_step"]] = ResultObsR_GLM[[i]]$Result$glm_step
  }
  
  ResultBaselineC$Result[["SVM"]] = ResultBaselineC_SVM$Result$SVM
  ResultBaselineR$Result[["SVM"]] = ResultBaselineR_SVM$Result$SVM
  
  ResultAbR$Result[["SVM"]] = ResultAbR_SVM$Result$SVM
  ResultAbC$Result[["SVM"]] = ResultAbC_SVM$Result$SVM
  
  ResultBaselineC$Result[["glm"]] = ResultBaselineC_GLM$Result$glm
  ResultBaselineR$Result[["glm"]] = ResultBaselineR_GLM$Result$glm
  
  ResultAbR$Result[["glm"]] = ResultAbR_GLM$Result$glm
  ResultAbC$Result[["glm"]] = ResultAbC_GLM$Result$glm
  
  ResultBaselineC$Result[["glm_step"]] = ResultBaselineC_GLM$Result$glm_step
  ResultBaselineR$Result[["glm_step"]] = ResultBaselineR_GLM$Result$glm_step
  
  ResultAbR$Result[["glm_step"]] = ResultAbR_GLM$Result$glm_step
  ResultAbC$Result[["glm_step"]] = ResultAbC_GLM$Result$glm_step
  
  
}
```

Tune classifiers' thresholds with the true skill statistic and aggregate results for both (classifier and regressor):
```{r,results=FALSE}
if(run){
  tune = tuneAndAggregate
  ResultSizeCagg = lapply(ResultSizeC, 
                          function(x) return(tune(x, tuneT = tss, bc = "None", onlyTest = F)))
  ResultObsCagg = lapply(ResultObsC, 
                         function(x) return(tune(x, TraitMatching::tss,"None", onlyTest = F)))
  ResultAbCagg = tune(ResultAbC, tuneT = TraitMatching::tss, bc = "None", onlyTest = F)
  
  ResultBaselineCagg = tune(ResultBaselineC, tuneT = TraitMatching::tss, bc = "None", onlyTest = F) 
  
  tune = tuneAndAggregateRegression
  ResultSizeRagg = lapply(ResultSizeR, 
                          function(x) return(tune(x,onlyTest = F)))
  ResultObsRagg = lapply(ResultObsR, 
                         function(x) return(tune(x, onlyTest = F))
                         )
  ResultAbRagg = tune(ResultAbR, onlyTest = F)
  ResultBaselineRagg = tune(ResultBaselineR, onlyTest = F) 

  
  save(ResultSizeCagg, ResultSizeRagg,ResultObsRagg, ResultObsCagg, ResultAbCagg, ResultAbRagg, ResultBaselineCagg, ResultBaselineRagg,
       file = "./Results/ResultsSimulationAgg.RData")
}
```


We computed tss, auc (rmse, spearman) for testing and training splits: 
```{r,results=FALSE}
load(file = "./Results/ResultsSimulationAgg.RData")
tss = auc =  tssObs = tssGenSize= aucObs = aucGenSize = data.frame(matrix(0,3,9))
baseC = aucAB = tssAB = baseCTSS = data.frame(matrix(0,1,9))
rmse = spear = rmseObs = spearGenObs = spearObs = spearGenSize = data.frame(matrix(0, 3, 7))
baseR=  baseRrmse = spearAB = rmseAB = data.frame(matrix(0, 1, 7))

methods = ResultSizeRagg[[1]][[8]][ResultSizeRagg[[1]][[8]]$set == "test",]$method
colnames(rmse) = colnames(spear) = methods
colnames(rmseObs) = colnames(spearObs) = methods
colnames(spearGenObs) = colnames(spearGenSize) = methods
colnames(spearAB) = colnames(rmseAB) = colnames(baseR) = colnames(rmseAB) = colnames(baseRrmse) =  methods

methods2 = ResultSizeCagg[[1]][[10]][ResultSizeCagg[[1]][[10]]$set == "test",c(1,11,13)]$method
colnames(tss) = colnames(auc) = methods2
colnames(aucObs) = colnames(tssObs) = methods2
colnames(aucGenSize) = colnames(tssGenSize) = colnames(baseCTSS)= methods2
colnames(aucAB) = colnames(tssAB) = colnames(baseC) = methods2

agg = function(d, m,  n) d[d$set == "test" & d$method == m, n]
aggT = function(d, m, n) d[d$set == "train" & d$method == m, n]
aucCheck = function(a) ifelse(a < 0.5, 1- a, a)
for(i in 1:3){
  for(k in 1:9){
    
    # Classification
    tss[i,k] = agg(ResultSizeCagg[[i]][[9+1]], colnames(tss)[k], 11)
   # tssAB[i,k] = agg(ResultAbCagg[[i]][[9+1]], colnames(tss)[k], 11)
    tssObs[i,k] = agg(ResultObsCagg[[i]][[9+1]], colnames(tss)[k], 11)
    
    auc[i,k] = agg(ResultSizeCagg[[i]][[9+1]], colnames(auc)[k], 1)
   # aucAB[i,k] = agg(ResultAbCagg[[i]][[9+1]], colnames(auc)[k], 1)
    aucObs[i,k] = agg(ResultObsCagg[[i]][[9+1]], colnames(auc)[k], 1)
    
    aucGenSize[i,k] = (aucCheck(aggT(ResultSizeCagg[[i]][[10]], colnames(auc)[k], 1))- aucCheck(auc[i,k]))/aucCheck(aggT(ResultSizeCagg[[i]][[10]], colnames(auc)[k], 1))
    
    tssGenSize[i,k] = (aggT(ResultSizeCagg[[i]][[10]], colnames(tss)[k], 11)-tss[i,k])/aggT(ResultSizeCagg[[i]][[10]], colnames(tss)[k], 11)
    # 
    # Regression
    if(k < 8){
      rmse[i,k] = agg(ResultSizeRagg[[i]][[8]], colnames(rmse)[k], 1)
      #rmseAB[i,k] = agg(ResultAbRagg[[i]][[6]], colnames(rmse)[k], 1)
      rmseObs[i,k] = agg(ResultObsRagg[[i]][[8]], colnames(rmse)[k], 1)
      spear[i,k] = abs(agg(ResultSizeRagg[[i]][[8]], colnames(spear)[k], 2))
      #spearAB[i,k] = abs(agg(ResultAbRagg[[i]][[6]], colnames(spear)[k], 2))
      spearObs[i,k] = abs(agg(ResultObsRagg[[i]][[8]], colnames(spear)[k], 2))
      spearGenSize[i,k] =(aggT(ResultSizeRagg[[i]][[8]], colnames(spear)[k], 2)-spear[i,k])/aggT(ResultSizeRagg[[i]][[8]], colnames(spear)[k], 2)
      spearGenObs[i,k] = (aggT(ResultObsRagg[[i]][[8]], colnames(spear)[k], 2)-spear[i,k])/aggT(ResultObsRagg[[i]][[8]], colnames(spear)[k], 2)
    }
    
    if(i == 1){
      aucAB[1,k] = agg(ResultAbCagg[[9+1]], colnames(auc)[k], 1)
      tssAB[1,k] = agg(ResultAbCagg[[9+1]], colnames(auc)[k], 11)
      baseC[1,k]  = agg(ResultBaselineCagg[[9+1]], colnames(auc)[k], 1)
      baseCTSS[1,k]  = agg(ResultBaselineCagg[[9+1]], colnames(auc)[k], 11)
      if(k < 8){
         rmseAB[1,k] = agg(ResultAbRagg[[8]], colnames(rmse)[k], 1)
         spearAB[1,k] = abs(agg(ResultAbRagg[[8]], colnames(spear)[k], 2))
         baseR[1,k] = agg(ResultBaselineRagg[[8]], colnames(rmse)[k], 2)
         baseRrmse[1,k] = agg(ResultBaselineRagg[[8]], colnames(rmse)[k], 1)

      }
      
    }
  }
}
# NA in boost:
baseR$boost = mean(ResultBaselineRagg$boost$test$Spearmanrho,na.rm = TRUE)

auc = as.data.frame(lapply(auc, function(x) ifelse(x < 0.5, 1-x, x)))
baseC = as.data.frame(lapply(baseC, function(x) ifelse(x < 0.5, 1-x, x)))
aucAB = as.data.frame(lapply(aucAB, function(x) ifelse(x < 0.5, 1-x, x)))
aucObs = as.data.frame(lapply(aucObs, function(x) ifelse(x < 0.5, 1-x, x)))

save(rmse, 
     rmseAB,
     rmseObs,
     baseRrmse,
     spear,
     spearAB,
     spearObs,
     spearGenObs, 
     spearGenSize,
     baseR,
     tss,
     tssAB,
     tssGenSize,
     tssObs,
     baseCTSS,
     auc,
     baseC,
     aucAB,
     aucObs,
     aucGenSize, 
     file = "./Results/SimulationAggreationFig2.RData")


# Confidence Intervals:

getCI = function(x) return(qnorm(0.975) * sd(x) / sqrt(length(x)))
tssCI = aucCI = aucObsCI = tssObsCI=data.frame(matrix(0,3,9))
baseCCI = aucABCI = tssABCI=  baseCTSSCI = data.frame(matrix(0,1,9))

len = length(ResultSizeCagg[[i]]) - 1
for(i in 1:3){
  for(j in 1:len){
    tssCI[i,j] = getCI(ResultSizeCagg[[i]][[j]]$test$tts)
    aucCI[i,j] = getCI(ResultSizeCagg[[i]][[j]]$test$auc)
    tssObsCI[i,j] = getCI(ResultObsCagg[[i]][[j]]$test$tts)
    aucObsCI[i,j] = getCI(ResultObsCagg[[i]][[j]]$test$auc)
    if(i == 1){
      baseCCI[1,j] = getCI(ResultBaselineCagg[[j]]$test$auc)
      aucABCI[1,j] = getCI(ResultAbCagg[[j]]$test$auc)
      tssABCI[1,j] = getCI(ResultAbCagg[[j]]$test$tts)
      baseCTSSCI[1,j] = getCI(ResultBaselineCagg[[j]]$test$tts)
    }
  }
}
colnames(tssCI) = colnames(aucCI) = colnames(aucObsCI) = colnames(tssObsCI) = names(ResultSizeCagg[[i]])[1:len]
colnames(aucABCI) = colnames(tssABCI) = names(ResultAbCagg)[1:len]
colnames(baseCTSSCI) = colnames(baseCCI) = names(ResultBaselineCagg)[1:len]



spearCI= spearObsCI  = data.frame(matrix(0,3,7))
baseRCI = spearABCI  =  data.frame(matrix(0,1,7))
len = length(ResultSizeRagg[[i]]) - 1

for(i in 1:3){
  for(j in 1:len){
    spearCI[i,j] = getCI(ResultSizeRagg[[i]][[j]]$test$Spearmanrho)
    spearObsCI[i,j] = getCI(ResultObsRagg[[i]][[j]]$test$Spearmanrho)
    if(i == 1){
      baseRCI[1,j] = getCI(ResultBaselineRagg[[j]]$test$Spearmanrho)
      spearABCI[1,j] = getCI(ResultAbRagg[[j]]$test$Spearmanrho)
    }
  }
}
colnames(spearCI) =  names(ResultSizeRagg[[i]])[1:len]
colnames(baseRCI) =  names(ResultBaselineRagg)[1:len]
colnames(spearABCI) =  names(ResultAbRagg)[1:len]
colnames(spearObsCI) = names(ResultObsRagg)[1:len]

save(tssCI, baseCCI, aucCI, aucABCI, tssABCI, baseCTSSCI, aucObsCI, tssObsCI, spearObsCI,
     spearCI, baseRCI, spearABCI,file = "./Results/SimulationAggreationCIFig2.RData")

```



# Plant-pollinator network

## Prepare Data 
```{r}
set.seed(42)
library(dplyr)
plantPollRaw<-read.csv("./Data/Raw/traits2_florian.csv",sep=";")

plantTraitsRaw<-plantPollRaw[,1:11]
insectTraitsRaw<-plantPollRaw[,12:ncol(plantPollRaw)]

colnames(plantTraitsRaw)[1] = "plant"
colnames(insectTraitsRaw)[1] = "insect"

interactionMatrix<-plantPollRaw[,-c(2:11,13:ncol(plantPollRaw))]
interactionMatrix<-xtabs(~.,data=interactionMatrix)
interactionMatrix<-as.data.frame.matrix(interactionMatrix)

data = TraitMatching::createCommunity(plantTraitsRaw, insectTraitsRaw, z = interactionMatrix)

saveRDS(data, file = "./Data/plantPoll.RDS")

```






## Predictive comparison on empirical plant-pollinator network
```{r,results=FALSE}
library(mlr)
library(TraitMatching)
library(tidyverse)
oldpar = par()
reset = function() suppressWarnings(do.call(par, oldpar))
source("./Code/helpFunctions.R")
```

### Train models
Training was splitted due to high computional cost
- 20 random tuning steps of hyper-parameter
- AUC evaluates tuning
- Nested cross-validation: ten-fold outer and three-fold inner with leaving out insect species+all of their interactions

```{r,results=FALSE}
set.seed(42)
if(run){
  cv = list(outer = list(method = "SpCV", iters = 5, predict = "both"), inner = list(method = "SpCV", iters = 3))
  
  
  
  cC = readRDS(file = "./Data/plantPoll.RDS")
  
  
  result = runTM(cC, tune = "random", iters = iter, tuningMetric = "auc", crossValidation = cv, block = T, parallel = parallel, fitSpecies = F, balanceClasses = c("Over"),
                 method = c("dnn", "cnn", "RFranger", "boost", "knn","naive", "glm"),
                settings = list(dnn = list(seed = 42,  activation = "relu", drop = 0.2, archFunction = "continous", epochs = epochs),
                          cnn = list(seed = 42, activation = "relu", drop = 0.2, nConv = 1, archFunction = "continous", epochs = epochs))
                )
  saveRDS(result, file = "./Results/CaseStudy1_Over.RDS")
  
}
```




## Results

Connect results and tune thresholds+computing of additional measurements
```{r,results=FALSE}
tune = FALSE
if(tune){
  
  raw = readRDS(file = "./Results/CaseStudy1_Over.RDS")
  svm = readRDS(file = "./Results/CaseStudy1_SVM.RDS")
  raw$Result[["SVM"]] = svm$Result$SVM
  
  
 
  Results = tuneAndAggregate(raw, tuneT = tss,onlyTest = F)
  
  saveRDS(Results, file = "./Results/aggregatedResults.RDS")
}


```

Prepare data for figure
```{r,results=FALSE}
Results = readRDS(file = "./Results/aggregatedResults.RDS")
test = Results$combinedTable[Results$combinedTable$set == "test",]
train = Results$combinedTable[Results$combinedTable$set == "train",]
colnames(test) = c("auc", "f1", "bac", "acc", "fdr", "fpr", "npv", "precision","specificity", "sensitivity", "tss", "set", "method")
colnames(train) = c("auc", "f1", "bac", "acc", "fdr", "fpr", "npv", "precision","specificity", "sensitivity", "tss", "set", "method")
test = test[order(test$tss, decreasing = T),]
bestTest = test[!duplicated(test$method),]
bestTest = bestTest[order(bestTest$auc),]
bestTrain = train[paste0(rep("tr",7),substr(rownames(bestTest),3,4)),]



```




