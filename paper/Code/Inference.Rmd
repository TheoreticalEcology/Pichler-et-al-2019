---
# title: "InferenceSimulation"
# author: "Max"
# date: "30 August 2018"
documentclass: report
fontsize: 11pt
header-includes:
   - \usepackage{longtable}
output:
  pdf_document: 
    highlight: monochrome
  html_document: 
    keep_md: yes
---
\pagenumbering{gobble} 


# Simulation

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE,warning = FALSE, error = F,tidy.opts=list(width.cutoff=40),tidy=TRUE , tidy = TRUE,size = "tiny")
hook_output = knitr::knit_hooks$get('output')
knitr::knit_hooks$set(output = function(x, options) {
  if (!is.null(n<- options$linewidth)) {
    x = knitr:::split_lines(x)
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})
library(TraitMatching)
library(iml)
library(mlr)
library(tidyverse)
oldpar = par()
reset = function() suppressWarnings(do.call(par, oldpar))
addA = function(col, alpha = 0.25) apply(sapply(col, col2rgb)/255, 2, function(x) rgb(x[1], x[2], x[3], alpha=alpha))
run = TRUE
set.seed(42)
```


## Test whether the top predictive models recognized simulated trait-matching





### Simulating TraitN and Trait Strengths 
#### Small


```{r}
library(TraitMatching)
set.seed(42)
simulation = simulate_batch(numberTraitsA = 7, numberTraitsB = 7, one_way = TRUE, NumberA = 25, NumberB = 50, 
                            cutoff = 0.5, strength_range = c(10,10), specRange = c(0.5, 1.2))

resultR = vector("list",4)

for(i in 1:length(simulation$data)){
  for(n in 1:length(simulation$data[[i]])) {
      resultR[[i]][[n]] = runTM(createCommunity(simulation$data[[i]][[n]]$A, 
                                               simulation$data[[i]][[n]]$B, 
                                               minOneInter(simulation$data[[i]][[n]]$poisson(simulation$res[[i]][[n]])), log = FALSE), 
                           method = c("negBinDnn", "RF", "boost", "knn"), 
            settings = list(negBinDnn = list(seed = 42,  activation = "relu",archFunction = "continous", epochs = 60,distribution = "poisson"),
                            boost = list(objective = "count:poisson")),
                         tune = "random", iters = 30,  fitSpecies = F,
                         crossValidation = list(outer = list(method = "Holdout", split = 4/5, predict = "both"), 
                                                inner = list(method = "Holdout", split = 4/5, predict = "both")), 
                         balanceClasses = "None", block = T, parallel = 10, seed = 42, keepModels = T,tuningMetric = "spearmanrho")
      saveRDS(resultR, file = "./Results/simulationTraitsAndStrengthsRegrWOabSimpleSMALL.RDS")
  }
}

resultC = vector("list", 4)
for(i in 1:length(simulation$data)){
  for(n in 1:length(simulation$data[[i]])) {
      resultC[[i]][[n]] = runTM(createCommunity(simulation$data[[i]][[n]]$A,
                                             simulation$data[[i]][[n]]$B, 
                                             minOneInter(simulation$data[[i]][[n]]$binar(simulation$res[[i]][[n]]))), 
                         method = c("dnn", "RF", "boost", "knn"), 
          settings = list(dnn = list(seed = 42,  activation = "relu",drop = 0.3, archFunction = "continous", epochs = 60)),
                       tune = "random", iters = 30,  fitSpecies = F,
                       crossValidation = list(outer = list(method = "Holdout", split = 4/5, predict = "both"), 
                                              inner = list(method = "Holdout", split = 4/5, predict = "both")), 
                       balanceClasses = "None", block = T, parallel = 10, seed = 42, keepModels = T)
    saveRDS(resultC, file = "./Results/simulationTraitsAndStrengthsClassifWOabSimpleSMALL.RDS")
  }
}


save(simulation, file = "./Results/simulationInterMetaDataSMALL.RData")


```



#### Small Interaction
```{r}
library(TraitMatching)
set.seed(42)
resultRegrWoAb = readRDS(file = "./Results/simulationTraitsAndStrengthsRegrWOabSimpleSMALL.RDS")
sim_len = sapply(resultRegrWoAb, length)
ind_matrix = data.frame(ind1 = rep(1:4,sim_len), ind2 = abind::abind(sapply(1:4, function(i) do.call(seq, list(1, sim_len[i])))))

cl = parallel::makePSOCKcluster(4)
doParallel::registerDoParallel(cl)
.null = parallel::clusterCall(cl, function(x) library(TraitMatching))

system.time({result_reg_small = snow::parSapply(cl = cl,X = 1:nrow(ind_matrix), FUN = function(i, ind_matrix, resultRegrWoAb){
  
  out = vector("list", 4)
  inds = unlist(ind_matrix[i,])
  data = mlr::normalizeFeatures(resultRegrWoAb[[1]][[1]]$classCommunity$data[,-c(1,2)], target = "target")
  
  for(m in 1:4){
    model = resultRegrWoAb[[inds[1]]][[inds[2]]]$Result[[m]]$result$models[[1]]
    out[[m]] = get_Interaction_Strengths(data, model, any = FALSE, depth = 7L,
                              groups = c("A", "B"), grid_size = 500L, 
                              target = "target", parallel = 7L
                               )
    gc()
  }
  gc()
  return(out)
  }, ind_matrix, resultRegrWoAb, simplify = FALSE)

})

saveRDS(result_reg_small, file = "./Results/res_reg_small.RDS")

```


```{r}
library(TraitMatching)
set.seed(42)
resultClassifWoAb = readRDS(file = "./Results/simulationTraitsAndStrengthsClassifWOabSimpleSMALL.RDS")
sim_len = sapply(resultClassifWoAb, length)
ind_matrix = data.frame(ind1 = rep(1:4,sim_len), ind2 = abind::abind(sapply(1:4, function(i) do.call(seq, list(1, sim_len[i])))))

cl = parallel::makePSOCKcluster(4)
doParallel::registerDoParallel(cl)
.null = parallel::clusterCall(cl, function(x) library(TraitMatching))

system.time({result_classif_small = snow::parSapply(cl = cl,X = 1:nrow(ind_matrix), FUN = function(i, ind_matrix, resultClassifWoAb){
  
  out = vector("list", 4)
  inds = unlist(ind_matrix[i,])
  data = mlr::normalizeFeatures(resultClassifWoAb[[1]][[1]]$classCommunity$data[,-c(1,2)], target = "target")
  
  for(m in 1:4){
    model = resultClassifWoAb[[inds[1]]][[inds[2]]]$Result[[m]]$result$models[[1]]
    out[[m]] = get_Interaction_Strengths(data, model, any = FALSE, depth = 7L,
                              groups = c("A", "B"), grid_size = 500L, 
                              target = "target", parallel = 7L
                               )
    gc()
  }
  gc()
  return(out)
  }, ind_matrix, resultClassifWoAb, simplify = FALSE)

})

saveRDS(result_classif_small, file = "./Results/res_classif_small.RDS")

```


#### Middle
```{r}
library(TraitMatching)
set.seed(42)
simulation = simulate_batch(numberTraitsA = 7, numberTraitsB = 7, one_way = TRUE, NumberA = 50, NumberB = 100, cutoff = 0.5, strength_range = c(10,10), specRange = c(0.5, 1.2))



resultR = vector("list",4)

for(i in 1:length(simulation$data)){
  for(n in 1:length(simulation$data[[i]])) {
      resultR[[i]][[n]] = runTM(createCommunity(simulation$data[[i]][[n]]$A, 
                                               simulation$data[[i]][[n]]$B, 
                                               minOneInter(simulation$data[[i]][[n]]$poisson(simulation$res[[i]][[n]])), log = FALSE), 
                           method = c("negBinDnn", "boost"), 
            settings = list(negBinDnn = list(seed = 42,  activation = "relu",archFunction = "continous", epochs = 60,distribution = "poisson"),
                            boost = list(objective = "count:poisson")),
                         tune = "random", iters = 30,  fitSpecies = F,
                         crossValidation = list(outer = list(method = "Holdout", split = 4/5, predict = "both"), 
                                                inner = list(method = "Holdout", split = 4/5, predict = "both")), 
                         balanceClasses = "None", block = T, parallel = 10, seed = 42, keepModels = T,tuningMetric = "poisson")
      saveRDS(resultR, file = "./Results/simulationTraitsAndStrengthsRegrWOabSimpleMIDDLE.RDS")
  }
}

resultC = vector("list", 4)
for(i in 1:length(simulation$data)){
  for(n in 1:length(simulation$data[[i]])) {
      resultC[[i]][[n]] = runTM(createCommunity(simulation$data[[i]][[n]]$A,
                                             simulation$data[[i]][[n]]$B, 
                                             minOneInter(simulation$data[[i]][[n]]$binar(simulation$res[[i]][[n]]))), 
                         method = c("dnn",  "boost"), 
          settings = list(dnn = list(seed = 42,  activation = "relu",drop = 0.3, archFunction = "continous", epochs = 60)),
                       tune = "random", iters = 30,  fitSpecies = F,
                       crossValidation = list(outer = list(method = "Holdout", split = 4/5, predict = "both"), 
                                              inner = list(method = "Holdout", split = 4/5, predict = "both")), 
                       balanceClasses = "None", block = T, parallel = 10, seed = 42, keepModels = T)
    saveRDS(resultC, file = "./Results/simulationTraitsAndStrengthsClassifWOabSimpleMIDDLE.RDS")
  }
}





save(simulation, file = "./Results/simulationInterMetaDataSMIDDLE.RData")


```


#### Middle Interaction
```{r}
library(TraitMatching)
set.seed(42)
resultRegrWoAb = readRDS(file = "./Results/simulationTraitsAndStrengthsRegrWOabSimpleMIDDLE.RDS")
sim_len = sapply(resultRegrWoAb, length)
ind_matrix = data.frame(ind1 = rep(1:4,sim_len), ind2 = abind::abind(sapply(1:4, function(i) do.call(seq, list(1, sim_len[i])), simplify = F) ))

cl = parallel::makePSOCKcluster(3)
doParallel::registerDoParallel(cl)
.null = parallel::clusterCall(cl, function(x) library(TraitMatching))

system.time({result_reg_small = snow::parSapply(cl = cl,X = 1:nrow(ind_matrix), FUN = function(i, ind_matrix, resultRegrWoAb){
  
  out = vector("list", 4)
  inds = unlist(ind_matrix[i,])
  data = mlr::normalizeFeatures(resultRegrWoAb[[1]][[1]]$classCommunity$data[,-c(1,2)], target = "target")
  
  for(m in 1:2){
    model = resultRegrWoAb[[inds[1]]][[inds[2]]]$Result[[m]]$result$models[[1]]
    print(model)
    out[[m]] = get_Interaction_Strengths(data, model, any = FALSE, depth = 7L,
                              groups = c("A", "B"), grid_size = 500L, 
                              target = "target", parallel = 3L
                               )
    gc()
  }
  gc()
  return(out)
  }, ind_matrix, resultRegrWoAb, simplify = FALSE)

})

saveRDS(result_reg_small, file = "./Results/res_reg_middle.RDS")

```

```{r}
library(TraitMatching)
set.seed(42)
resultClassifWoAb = readRDS(file = "../Results/simulationTraitsAndStrengthsClassifWOabSimpleMIDDLE.RDS")
sim_len = sapply(resultClassifWoAb, length)
ind_matrix = data.frame(ind1 = rep(1:4,sim_len), ind2 = abind::abind(sapply(1:4, function(i) do.call(seq, list(1, sim_len[i])),simplify = F)))

cl = parallel::makePSOCKcluster(2)
doParallel::registerDoParallel(cl)
.null = parallel::clusterCall(cl, function(x) library(TraitMatching))

system.time({result_classif_middle = snow::parSapply(cl = cl,X = 1:nrow(ind_matrix), FUN = function(i, ind_matrix, resultClassifWoAb){
  
  out = vector("list", 4)
  inds = unlist(ind_matrix[i,])
  data = mlr::normalizeFeatures(resultClassifWoAb[[1]][[1]]$classCommunity$data[,-c(1,2)], target = "target")
  
  for(m in 1:2){
    model = resultClassifWoAb[[inds[1]]][[inds[2]]]$Result[[m]]$result$models[[1]]
    out[[m]] = get_Interaction_Strengths(data, model, any = FALSE, depth = 7L,
                              groups = c("A", "B"), grid_size = 500L, 
                              target = "target", parallel = 3L
                               )
    gc()
  }
  gc()
  return(out)
  }, ind_matrix, resultClassifWoAb, simplify = FALSE)

})

saveRDS(result_classif_middle, file = "../Results/res_classif_middle.RDS")

```

### Results
#### Small
```{r}
regrRes = readRDS(file = "./Results/res_reg_small.RDS")
classRes = readRDS(file = "./Results/res_classif_small.RDS")

studyResReg = readRDS(file = './Results/simulationTraitsAndStrengthsRegrWOabSimpleSMALL.RDS')
studyClassReg = readRDS(file = './Results/simulationTraitsAndStrengthsClassifWOabSimpleSMALL.RDS')

load(file = './Results/simulationInterMetaDataSMALL.RData')

library(TraitMatching)

TraitInter = simulation$TraitInter

TraitInter = lapply(1:4, function(i){
  ind = matrix(1:ncol(TraitInter[[i]]), ncol = 2,byrow = T)
  out = matrix("", nrow = 10, ncol = ncol(TraitInter[[i]])*0.5)
  for(j in 1:nrow(ind)) {
    out[,j] = apply(TraitInter[[i]][,ind[j,]], 1, function(x) paste0(x[1], ":", x[2]))
  }
  return(out)
})


# update metda:
TraitInter = lapply(1:4, function(i) {
  lapply(1:10, function(j) if(simulation$survived_interactions[[i]][j] >= 0.5*25*50) return(TraitInter[[i]][j,]) else return(NULL))
})

TraitStrengths = lapply(1:4, function(i) {
  lapply(1:10, function(j) if(simulation$survived_interactions[[i]][j] >= 0.5*25*50) return(simulation$TraitStrengths[[i]][j,]) else return(NULL))
})

for(i in 1:4){
  TraitStrengths[[i]][sapply(TraitStrengths[[i]], is.null)] <- NULL
  TraitInter[[i]][sapply(TraitInter[[i]], is.null)] <- NULL
}

aggResRegr = aggregate_interaction_result(model_result = studyResReg, inter_results = regrRes,trait_inter = TraitInter, trait_strengths = TraitStrengths)

aggResClass = aggregate_interaction_result(model_result = studyClassReg, inter_results = classRes,trait_inter = TraitInter, trait_strengths = TraitStrengths)

sim_len = sapply(studyResReg, length)
ind_matrix = data.frame(ind1 = rep(1:4,sim_len), ind2 = abind::abind(sapply(1:4, function(i) do.call(seq, list(1, sim_len[i])), simplify = F) ))

aggResRegr$repetition = rep(unlist(apply(ind_matrix, 1, function(x) rep(x[2], x[1]))), rep(4, length(unlist(apply(ind_matrix, 1, function(x) rep(x[2], x[1]))))))
aggResClass$repetition = rep(unlist(apply(ind_matrix, 1, function(x) rep(x[2], x[1]))), rep(4, length(unlist(apply(ind_matrix, 1, function(x) rep(x[2], x[1]))))))


resAggSmallReg = aggTrpRep(aggTrp(aggResRegr), aggResRegr)
resAggSmallClass = aggTrpRep(aggTrp(aggResClass), aggResClass)
save(resAggSmallReg, file = "./Results/resAggMiddleReg.RDS")
save(resAggSmallClass, file = "./Results/resAggMiddleReg.RDS")

```

#### Middle
```{r}

regrRes = readRDS(file = "../Results/res_reg_middle.RDS")
classRes = readRDS(file = "../Results/res_classif_middle.RDS")

studyResReg = readRDS(file = '../Results/simulationTraitsAndStrengthsRegrWOabSimpleMIDDLE.RDS')
studyClassReg = readRDS(file = '../Results/simulationTraitsAndStrengthsClassifWOabSimpleMIDDLE.RDS')

load(file = '../Results/simulationInterMetaDataSMIDDLE.RData')

library(TraitMatching)

TraitInter = simulation$TraitInter

TraitInter = lapply(1:4, function(i){
  ind = matrix(1:ncol(TraitInter[[i]]), ncol = 2,byrow = T)
  out = matrix("", nrow = 10, ncol = ncol(TraitInter[[i]])*0.5)
  for(j in 1:nrow(ind)) {
    out[,j] = apply(TraitInter[[i]][,ind[j,]], 1, function(x) paste0(x[1], ":", x[2]))
  }
  return(out)
})


# update metda:
TraitInter = lapply(1:4, function(i) {
  lapply(1:10, function(j) if(simulation$survived_interactions[[i]][j] >= 0.5*25*50) return(TraitInter[[i]][j,]) else return(NULL))
})

TraitStrengths = lapply(1:4, function(i) {
  lapply(1:10, function(j) if(simulation$survived_interactions[[i]][j] >= 0.5*25*50) return(simulation$TraitStrengths[[i]][j,]) else return(NULL))
})

for(i in 1:4){
  TraitStrengths[[i]][sapply(TraitStrengths[[i]], is.null)] <- NULL
  TraitInter[[i]][sapply(TraitInter[[i]], is.null)] <- NULL
}


aggResRegr = aggregate_interaction_result(model_result = studyResReg, inter_results = regrRes,trait_inter = TraitInter, trait_strengths = TraitStrengths)

aggResClass = aggregate_interaction_result(model_result = studyClassReg, inter_results = classRes,trait_inter = TraitInter, trait_strengths = TraitStrengths)

aggResRegr$repetition = rep(unlist(apply(ind_matrix, 1, function(x) rep(x[2], x[1]))), rep(2, length(unlist(apply(ind_matrix, 1, function(x) rep(x[2], x[1]))))))
aggResClass$repetition = rep(unlist(apply(ind_matrix, 1, function(x) rep(x[2], x[1]))), rep(2, length(unlist(apply(ind_matrix, 1, function(x) rep(x[2], x[1]))))))

resAggMiddleReg = aggTrpRep(aggTrp(aggResRegr), aggResRegr)
resAggMiddleClass = aggTrpRep(aggTrp(aggResClass), aggResClass)
save(resAggMiddleReg, file = "./Results/resAggMiddleReg.RDS")
save(resAggMiddleClass, file = "./Results/resAggMiddleReg.RDS")

```







# Hummingbird-plant network


```{r,results=FALSE}

inH = read.csv("./PlantBird/interact_matrix_high.csv")
inM = read.csv("./PlantBird/interact_matrix_mid.csv")
inL = read.csv("./PlantBird/interact_matrix_low.csv")

tbH = read.csv("./PlantBird/traitbird_high.csv",col.names = c("Hummingbird", "Bill.Length", "Bill.Curvature", "Body.Mass", "Wing", "Tail")) %>% normalizeFeatures(method = "center")
tbM = read.csv("./PlantBird/traitbird_mid.csv",col.names = c("Hummingbird", "Bill.Length", "Bill.Curvature", "Body.Mass", "Wing", "Tail")) %>% normalizeFeatures(method = "center")
tbL = read.csv("./PlantBird/traitbird_low.csv",col.names = c("Hummingbird", "Bill.Length", "Bill.Curvature", "Body.Mass", "Wing", "Tail")) %>% normalizeFeatures(method = "center")

tpH = read.csv("./PlantBird/traitplant_high.csv", col.names = c("Plant", "Corolla.Length", "Corolla.Curvature", "Corolla.Volumen", "Inner.Diameter", "Ext.Diameter", "NumIndividuals")) %>% normalizeFeatures(method = "center", cols = c("Corolla.Length", "Corolla.Curvature", "Corolla.Volumen", "Inner.Diameter", "Ext.Diameter"))
tpM = read.csv("./PlantBird/traitplant_mid.csv", col.names = c("Plant", "Corolla.Length", "Corolla.Curvature", "Corolla.Volumen", "Inner.Diameter", "Ext.Diameter", "NumIndividuals")) %>% normalizeFeatures(method = "center", cols = c("Corolla.Length", "Corolla.Curvature", "Corolla.Volumen", "Inner.Diameter", "Ext.Diameter"))
tpL = read.csv("./PlantBird/traitplant_low.csv", col.names = c("Plant", "Corolla.Length", "Corolla.Curvature", "Corolla.Volumen", "Inner.Diameter", "Ext.Diameter", "NumIndividuals")) %>% normalizeFeatures(method = "center", cols = c("Corolla.Length", "Corolla.Curvature", "Corolla.Volumen", "Inner.Diameter", "Ext.Diameter"))


rownames(inH) = as.character(inH$X)
inH = inH[,-1]
rownames(inM) = as.character(inM$X)
inM = inM[,-1]
rownames(inL) = as.character(inL$X)
inL = inL[,-1]


```





### Train models
Create combinations of networks and fit learner in 60 tuning steps with three-fold cross-validation

```{r,results=FALSE}
if(run){
  tbH_c = tbH
  tbM_c = tbM
  tbL_c = tbL
  tbH_c$plot = as.factor(rep("High", nrow(tbH)))
  tbM_c$plot = as.factor(rep("Mid", nrow(tbM)))
  tbL_c$plot = as.factor(rep("Low", nrow(tbL)))
  
  communityCombined =  createCommunity(community = list(list(tpH, tbH_c, inH), list(tpM, tbM_c, inM), list(tpL, tbL_c, inL)),log = F)
  communityCombined$data = communityCombined$data %>% mutate(target = target/NumIndividuals) %>% 
    select(-NumIndividuals) %>% createDummyFeatures(cols = "plot") 
  
  
  Low = LowMid = LowHigh = MidHigh = High = Mid = all =  communityCombined
  Low$data = communityCombined$data[communityCombined$data$plot.Low > 0 ,1:13 ] %>% normalizeFeatures(target = "target")
  Low$block = communityCombined$block[communityCombined$data$plot.Low > 0 ,]
  
  LowMid$data = communityCombined$data[communityCombined$data$plot.Low > 0 | communityCombined$data$plot.Mid > 0,c(1:13)] %>% normalizeFeatures(target = "target")
  LowMid$block = communityCombined$block[communityCombined$data$plot.Low > 0 | communityCombined$data$plot.Mid > 0,]
  
  LowHigh$data = communityCombined$data[communityCombined$data$plot.Low > 0 | communityCombined$data$plot.High > 0,c(1:13)] %>% normalizeFeatures(target = "target")
  LowHigh$block = communityCombined$block[communityCombined$data$plot.Low > 0 | communityCombined$data$plot.High > 0,]
  
  MidHigh$data = communityCombined$data[communityCombined$data$plot.Mid > 0 | communityCombined$data$plot.High > 0,c(1:13)] %>% normalizeFeatures(target = "target")
  MidHigh$block = communityCombined$block[communityCombined$data$plot.Mid > 0 | communityCombined$data$plot.High > 0,]
  
  High$data = communityCombined$data[communityCombined$data$plot.High > 0 ,1:13 ] %>% normalizeFeatures(target = "target")
  High$block = communityCombined$block[communityCombined$data$plot.High > 0 ,]
  
  Mid$data = communityCombined$data[communityCombined$data$plot.Mid > 0 ,1:13 ] %>% normalizeFeatures(target = "target")
  Mid$block = communityCombined$block[communityCombined$data$plot.Mid > 0 ,]
  
  all$data = communityCombined$data %>% normalizeFeatures(target = "target")
  all$block = communityCombined$block[,]
  
  community = list(Low = Low,
                   Mid = Mid,
                   High = High,
                   MidHigh = MidHigh,
                   LowMid = LowMid,
                   LowHigh = LowHigh,
                   all = all
                   )
  
  # two DNN: Poisson and negative binomial distributions
  
  learnerNegBinDnn = makeLearner("regr.negBinDnn",seed = 42, batch = 25,archFunction = "continous", distribution = "negBin", epochs = 60)
  learnerPoissonDnn = makeLearner("regr.negBinDnn",seed = 42, batch = 25,archFunction = "continous", distribution = "poisson", epochs = 60)
  learnerRF = makeLearner("regr.randomForest", predict.type = "se")
  learnerBoost = makeLearner("regr.xgboost", objective = "count:poisson")
  parDnn = makeParamSet(makeNumericParam("lr", lower = 0.0001, upper = 0.01),
                        makeIntegerParam("arch", lower = 5L, upper = 35L),
                        makeIntegerParam("nLayer", 1, 5),
                        makeLogicalParam("bias", default = T)
                        )
  
  parRF = makeParamSet(makeIntegerParam("mtry",lower = 2,upper = 10),         
                        makeIntegerParam("nodesize",lower = 2,upper = 50))
  parBoost <- makeParamSet(makeDiscreteParam("booster", values = c("gbtree", "dart")),
                          makeDiscreteParam("sample_type", values = c("uniform", "weighted"), requires = quote(booster == "dart")),
                          makeDiscreteParam("normalize_type", values = c("tree", "forest"), requires = quote(booster == "dart")),
                          makeNumericParam("eta", lower = 0.01, upper = 0.5),
                          makeNumericParam("gamma", lower = -9, upper = 5, trafo = function(x) 2^x),
                          makeIntegerParam("max_depth", lower = 1, upper = 10),
                          makeNumericParam("lambda", lower = -1, upper = 0, trafo = function(x) 10^x),
                          makeNumericParam("alpha", lower = -10, upper = 5, trafo = function(x) 2^x),
                          makeNumericParam("min_child_weight", 0, 10),
                          makeIntegerParam("nrounds", lower = 20, upper = 300),
                          makeNumericParam("rate_drop", lower = 0, upper = 0.2, requires = quote(booster == "dart")),
                          makeNumericParam("skip_drop", lower = 0, upper = 0.3, requires = quote(booster == "dart")))
  
  
  
  modelNegBin = vector("list", 7)
  modelRF = vector("list", 7)
  modelPoisson= vector("list", 7)
  modelBoost = vector("list",7)
  parallelMap::parallelStartSocket(cpus = 30, level = "mlr.tuneParams")
  predictLearner.regr.negBinDnn = TraitMatching:::predictLearner.regr.negBinDnn
  trainLearner.regr.negBinDnn = TraitMatching:::trainLearner.regr.negBinDnn
  parallelMap::parallelExport("trainLearner.regr.negBinDnn", "predictLearner.regr.negBinDnn", level = "mlr.tuneParams")
  
  
  
  for(i in 1:7){
   set.seed(42)
    task = makeRegrTask(data = community[[i]]$data[,-c(1,2)], target = "target", coordinates = community[[i]]$block)
    
    modelNegBin[[i]] = mlr::train(setHyperPars(learnerNegBinDnn,par.vals =  tuneParams(learnerNegBinDnn, par.set = parDnn,
                                                               control = makeTuneControlRandom(maxit = 60),measures = spearmanrho,show.info = T,
                                                              task = task, resampling = makeResampleDesc("SpCV", iters = 3))$x)
                              ,task = task)
  
    modelPoisson[[i]] = mlr::train(setHyperPars(learnerPoissonDnn,par.vals =  tuneParams(learnerNegBinDnn, par.set = parDnn,
                                                               control = makeTuneControlRandom(maxit = 60),measures = spearmanrho,show.info = T,
                                                              task = task, resampling = makeResampleDesc("SpCV", iters = 3))$x)
                              ,task = task)
    
    modelRF[[i]] = mlr::train(setHyperPars(learnerRF,par.vals =  tuneParams(learnerRF, par.set = parRF,
                                                              control = makeTuneControlRandom(maxit = 60),measures = spearmanrho,show.info = T,
                                                              task = task, resampling = makeResampleDesc("SpCV", iters = 3))$x)
                              ,task = task)
    modelBoost[[i]] = mlr::train(setHyperPars(learnerBoost,par.vals =  tuneParams(learnerBoost, par.set = parBoost,
                                                              control = makeTuneControlRandom(maxit = 60),measures = spearmanrho,show.info = T,
                                                              task = task, resampling = makeResampleDesc("SpCV", iters = 3))$x)
                              ,task = task)
  
  
  }
  names(modelNegBin) = names(community)
  names(modelPoisson) = names(community)
  names(modelRF) = names(community)
  names(modelBoost) = names(community)
  
  save(modelRF, modelBoost, modelNegBin, modelPoisson, community, file = "./Results/HummingBirdResult.RData")
}


```


```{r,results=FALSE}
load(file = "./Results/HummingBirdResult.RData")
```

### Compute overall+pairwise interaction strengths


```{r,results=FALSE}
if(run){
  set.seed(42)
  models = list(boost = modelBoost, negbin = modelNegBin, poisson = modelPoisson, rf = modelRF)
  
  
  ResultInterLow = list()
  for(i in names(models)){
      cat(i)
      ResultInterLow[[i]] = 
        get_Interaction_Strengths(data = community$Low$data[,-c(1,2)], model = models[[i]][["Low"]], any = FALSE, depth = 10L,
                              groups = NULL, grid_size = nrow(community$Low$data[,-c(1,2)]), 
                              target = "target", parallel = 10L
                               )
  }
  
  ResultInterMid= list()
  for(i in names(models)){
      cat(i)
    ResultInterMid[[i]] =
      get_Interaction_Strengths(data = community$Mid$data[,-c(1,2)], model = models[[i]][["Mid"]], any = FALSE, depth = 10L,
                              groups = NULL, grid_size = nrow(community$Mid$data[,-c(1,2)]), 
                              target = "target", parallel = 10L
                               )
    gc()
  }
  
  ResultInterHigh = list()
  for(i in names(models)){
      cat(i)
    ResultInterHigh[[i]]=
      get_Interaction_Strengths(data = community$High$data[,-c(1,2)], model = models[[i]][["High"]], any = FALSE, depth = 10L,
                              groups = NULL, grid_size = nrow(community$High$data[,-c(1,2)]), 
                              target = "target", parallel = 10L
                               )
    gc()
  }
  
  ResultInterCombined = list()
  for(i in names(models)){
      cat(i)
    ResultInterCombined[[i]] =
      get_Interaction_Strengths(data = community$all$data[,-c(1,2)], model = models[[i]][["all"]], any = FALSE, depth = 13L,
                              groups = NULL, grid_size = nrow(community$all$data[,-c(1,2)]), 
                              target = "target", parallel = 13L
                               )
    gc()
  }
  
  save(ResultInterLow,ResultInterMid,ResultInterHigh,ResultInterCombined, file = "./Results/HummingInferenceResult.RData")
}

```


