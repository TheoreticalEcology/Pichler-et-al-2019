---
# title: "InferenceSimulation"
# author: "Max"
# date: "30 August 2018"
documentclass: report
fontsize: 11pt
header-includes:
   - \usepackage{longtable}
output:
  pdf_document: 
    highlight: monochrome
  html_document: 
    keep_md: yes
---
\pagenumbering{gobble} 


# Simulation

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE,warning = FALSE, error = F,tidy.opts=list(width.cutoff=40),tidy=TRUE , tidy = TRUE,size = "tiny")
hook_output = knitr::knit_hooks$get('output')
knitr::knit_hooks$set(output = function(x, options) {
  if (!is.null(n<- options$linewidth)) {
    x = knitr:::split_lines(x)
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})
library(TraitMatching)
library(iml)
library(mlr)
library(tidyverse)
oldpar = par()
reset = function() suppressWarnings(do.call(par, oldpar))
addA = function(col, alpha = 0.25) apply(sapply(col, col2rgb)/255, 2, function(x) rgb(x[1], x[2], x[3], alpha=alpha))
run = TRUE
set.seed(42)
```


## Test whether the top predictive models recognized simulated trait-matching
<!-- ### Compute top four overall and for each the top two pairwise interacting features -->
<!-- ```{r,results=FALSE} -->
<!-- if(run){ -->

<!--   ResultSizeC = readRDS(file = "./Results/simSizeC.RDS") -->
<!--   ResultSizeR = readRDS(file = "./Results/simSizeR.RDS") -->


<!--   ResultAbC = readRDS(file = "./Results/simAbC.RDS") -->
<!--   ResultAbR = readRDS(file = "./Results/simAbR.RDS") -->

<!--   getInteractions = function(model, data, classif = T, ll = T, n = 10){ -->
<!--       set.seed(42) -->
<!--       library(iml) -->
<!--       library(doParallel) -->
<!--       cl = makePSOCKcluster(n) -->
<!--       registerDoParallel(cl) -->
<!--       results = list() -->
<!--       predictor = Predictor$new(model = model, data = data[,-10], y =data[,10], batch.size = 200) -->

<!--       if(classif) loss = "ce" -->
<!--       else { -->
<!--         if(ll) loss = function(actual, predicted) sum(-2*dpois(round(actual),predicted, log = T)) -->
<!--         else loss = "rmse" -->
<!--       } -->

<!--       results[["featureImportance"]] = iml::FeatureImp$new(predictor, loss = loss,parallel = TRUE)$results -->

<!--       AllInteractions = iml::Interaction$new(predictor, parallel = TRUE, grid.size = 200)$results -->
<!--       AllInteractions = AllInteractions[order(AllInteractions$.interaction, decreasing = T),] -->
<!--       if(classif) AllInteractions = AllInteractions[AllInteractions$.class == "positive",] -->

<!--       results[["first"]] = iml::Interaction$new(predictor,  feature = AllInteractions$.feature[1], parallel = TRUE, grid.size = 200)$results -->
<!--       results$first = results$first[order(results$first$.interaction, decreasing = T),] -->
<!--       if(classif) results$first = results$first[results$first$.class == "positive",] -->

<!--       results[["second"]] = iml::Interaction$new(predictor,  feature = AllInteractions$.feature[2], parallel = TRUE, grid.size = 200)$results -->
<!--       results$second = results$second[order(results$second$.interaction, decreasing = T),] -->
<!--       if(classif) results$second = results$second[results$second$.class == "positive",] -->

<!--       results[["third"]] = iml::Interaction$new(predictor,  feature = AllInteractions$.feature[3], parallel = TRUE, grid.size = 200)$results -->
<!--       results$third = results$third[order(results$third$.interaction, decreasing = T),] -->
<!--       if(classif) results$third = results$third[results$third$.class == "positive",] -->

<!--       results[["fourth"]] = iml::Interaction$new(predictor,  feature = AllInteractions$.feature[4], parallel = TRUE, grid.size = 200)$results -->
<!--       results$fourth = results$fourth[order(results$fourth$.interaction, decreasing = T),] -->
<!--       if(classif) results$fourth = results$fourth[results$fourth$.class == "positive",] -->

<!--       try(stopImplicitCluster()) -->
<!--       try(stopCluster(cl)) -->

<!--       results[["All"]] = AllInteractions -->
<!--       gc() -->
<!--       return(results) -->
<!--   } -->

<!--   # Classification -->
<!--   data = createDummyFeatures(ResultSizeC[[2]]$classCommunity$data[,-c(1,2)], target = "target") -->
<!--   data = normalizeFeatures(data, target = "target") -->

<!--   ResultClassifInteraction = list() -->
<!--   for(i in 1:7){ -->
<!--     if(names(ResultSizeC[[2]]$Result)[i] %in% c("dnn", "RF", "boost")){ -->
<!--       cat(names(ResultSizeC[[2]]$Result)[i]) -->
<!--       n = names(ResultSizeC[[2]]$Result)[i] -->
<!--       dR = ResultSizeC[[2]]$Result[[i]]$result$models[[1]] -->
<!--       ResultClassifInteraction[[n]] =  -->
<!--         getInteractions(dR,data,classif = TRUE) -->
<!--     } -->
<!--     gc() -->
<!--   } -->


<!--   data = createDummyFeatures(ResultAbC[[2]]$classCommunity$data[,-c(1,2)], target = "target") -->
<!--   data = normalizeFeatures(data, target = "target") -->

<!--   ResultClassifInteractionAb = list() -->
<!--   for(i in 1:7){ -->
<!--     if(names(ResultAbC[[2]]$Result)[i] %in% c("dnn", "RF", "boost")){ -->
<!--       cat("\n",names(ResultAbC[[2]]$Result)[i]) -->
<!--       n = names(ResultAbC[[2]]$Result)[i] -->
<!--       dR = ResultAbC[[2]]$Result[[i]]$result$models[[1]] -->
<!--       ResultClassifInteractionAb[[n]] =  -->
<!--         getInteractions(dR,data,classif = TRUE) -->
<!--     } -->
<!--     gc() -->
<!--   } -->

<!--   save(ResultClassifInteractionAb, ResultClassifInteraction, file = "Results/InferenceTop4Class.RData") -->

<!--   # Regression -->
<!--   dataReg = createDummyFeatures(ResultSizeR[[2]]$classCommunity$data[,-c(1,2)], target = "target") -->
<!--   dataReg = normalizeFeatures(dataReg, target = "target") -->

<!--   ResultRegrInteraction = list() -->
<!--   for(i in 1:5){ -->

<!--     if(names(ResultSizeR[[2]]$Result)[i] %in% c("negBinDnn", "RF", "boost")){ -->
<!--       cat(names(ResultSizeR[[2]]$Result)[i]) -->
<!--       if(names(ResultAbR[[2]]$Result)[i] == "RF") ll = FALSE -->
<!--       else ll = TRUE -->
<!--       n = names(ResultSizeR[[2]]$Result)[i] -->
<!--       dR = ResultSizeR[[2]]$Result[[i]]$result$models[[1]] -->
<!--       if(names(ResultSizeR[[2]]$Result)[i]  %in% c("RF","boost")) nCores = 3 -->
<!--       else nCores = 14 -->
<!--       ResultRegrInteraction[[n]] = getInteractions(dR,dataReg, classif = FALSE, ll = ll, n = nCores) -->
<!--     } -->
<!--     gc() -->
<!--   } -->

<!--   dataReg = createDummyFeatures(ResultAbR[[2]]$classCommunity$data[,-c(1,2)], target = "target") -->
<!--   dataReg = normalizeFeatures(dataReg, target = "target") -->

<!--   ResultRegrInteractionAB = list() -->
<!--   for(i in 1:5){ -->
<!--     if(names(ResultAbR[[2]]$Result)[i] %in% c("negBinDnn", "RF", "boost")){ -->
<!--       cat(names(ResultSizeR[[2]]$Result)[i]) -->
<!--       if(names(ResultAbR[[2]]$Result)[i] == "RF") ll = FALSE -->
<!--       else ll = TRUE -->
<!--       n = names(ResultAbR[[2]]$Result)[i] -->
<!--       dR = ResultAbR[[2]]$Result[[i]]$result$models[[1]] -->
<!--       ResultRegrInteractionAB[[n]] = getInteractions(dR,dataReg,classif = FALSE, ll = ll) -->
<!--     } -->
<!--     gc() -->
<!--   } -->

<!--   save(ResultRegrInteraction, ResultRegrInteractionAB, file = "Results/InferenceTop4Reg.RData") -->
<!-- } -->

<!-- ``` -->

<!-- ### Compute change in response of true trait interactions from the models -->
<!-- Real Interactions: -->
<!-- A1 - B2 -->
<!-- A2 - B3 -->
<!-- A3 - B4 -->







<!-- ```{r} -->
<!-- reset() -->
<!-- cex = 1.2 -->
<!-- par(mfrow = c(1,3), mar = c(0.3,0.2,0.6,0.1)+0.1,oma = c(1,0.7,0.2,0.1) ,xaxs = "i", yaxs = "i", pty = "s") -->
<!-- rowchart(ResultClassifInteractionAb$RF, true, cex = cex) -->
<!-- rowchart(ResultClassifInteractionAb$dnn, true, cex = cex) -->
<!-- rowchart(ResultClassifInteractionAb$boost, true, cex = cex) -->

<!-- ``` -->




<!-- Prepare plots, calculate respones for models -->
<!-- ### Mid -->
<!-- ```{r} -->
<!-- if(run){ -->
<!--   library(ALEPlot) -->
<!--   set.seed(42) -->
<!--   # A2/B3 + A3/B4 -->
<!--   dataC = normalizeFeatures(createDummyFeatures(ResultAbC[[2]]$classCommunity$data[,-c(1,2)], target = "target"), target = "target") -->
<!--   newPredictC = function(X.model, newdata) predict(X.model, newdata=newdata)$data[,2]  -->
<!--   A2_B3_Classifier = A3_B4_Classifier = vector("list",3) -->
<!--   modelNames = c("RF", "dnn", "boost") -->
<!--   for(i in 1:3) { -->
<!--     A2_B3_Classifier[[i]] = ALEPlot(X = dataC[,-10], X.model = ResultAbC[[2]]$Result[[modelNames[i]]]$result$models[[1]], pred.fun = newPredictC, J = c(1,6), K = 80) -->
<!--     A3_B4_Classifier[[i]] = ALEPlot(X = dataC[,-10], X.model = ResultAbC[[2]]$Result[[modelNames[i]]]$result$models[[1]], pred.fun = newPredictC, J = c(2,7), K = 80) -->
<!--   } -->

<!--   newPredictR = function(X.model, newdata) predict(X.model, newdata=newdata)$data[,1]  -->
<!--   dataR = normalizeFeatures(createDummyFeatures(ResultAbR[[2]]$classCommunity$data[,-c(1,2)], target = "target"), target = "target") -->
<!--   A2_B3_Regressor = A3_B4_Regressor=vector("list",3) -->
<!--   modelNames = c("RF", "negBinDnn", "boost") -->
<!--   for(i in 1:3) { -->
<!--     A2_B3_Regressor[[i]] = ALEPlot(X = dataR[,-10], X.model = ResultAbR[[2]]$Result[[modelNames[i]]]$result$models[[1]], pred.fun = newPredictR, J = c(1,6), K = 80) -->
<!--     A3_B4_Regressor[[i]] = ALEPlot(X = dataR[,-10], X.model = ResultAbR[[2]]$Result[[modelNames[i]]]$result$models[[1]], pred.fun = newPredictR, J = c(2,7), K = 80) -->
<!--   } -->

<!--   # A1 + B2 -->
<!--   first = sort(unique(dataC$A1.1),decreasing = T) -->
<!--   second = sort(unique(dataC$A1.2),decreasing = T) -->
<!--   dataCnn = normalizeFeatures(createDummyFeatures(ResultAbC[[2]]$classCommunity$data[,-c(1,2)], target = "target", cols = "B1"), target = "target") -->
<!--   newPredictC = function(X.model, newdata){ -->
<!--     newdata = createDummyFeatures(newdata) -->
<!--     newdata$A1.1 = ifelse(newdata$A1.1 > 0, first[1],first[2]) -->
<!--     newdata$A1.2 = ifelse(newdata$A1.2 > 0, second[1],second[2]) -->
<!--     return(predict(X.model, newdata=newdata)$data[,2] ) -->
<!--   } -->
<!--   A1_B2_Classifier = vector("list",3) -->
<!--   modelNames = c("RF", "dnn", "boost") -->
<!--   for(i in 1:3) A1_B2_Classifier[[i]] = ALEPlot(X = dataCnn[,-11], X.model = ResultAbC[[2]]$Result[[modelNames[i]]]$result$models[[1]], pred.fun = newPredictC, J = c(1,6), K = 80) -->


<!--   first = sort(unique(dataR$A1.1),decreasing = T) -->
<!--   second = sort(unique(dataR$A1.2),decreasing = T) -->
<!--   dataRnn = normalizeFeatures(createDummyFeatures(ResultAbR[[2]]$classCommunity$data[,-c(1,2)], target = "target", cols = "B1"), target = "target") -->
<!--   newPredictR = function(X.model, newdata){ -->
<!--     newdata = createDummyFeatures(newdata) -->
<!--     newdata$A1.1 = ifelse(newdata$A1.1 > 0, first[1],first[2]) -->
<!--     newdata$A1.2 = ifelse(newdata$A1.2 > 0, second[1],second[2]) -->
<!--     return(predict(X.model, newdata=newdata)$data[,1] ) -->
<!--   } -->
<!--   A1_B2_Regressor = vector("list",3) -->
<!--   modelNames = c("RF", "negBinDnn", "boost") -->
<!--   for(i in 1:3) A1_B2_Regressor[[i]] = ALEPlot(X = dataRnn[,-11], X.model = ResultAbR[[2]]$Result[[modelNames[i]]]$result$models[[1]], pred.fun = newPredictR, J = c(1,6), K = 80) -->
<!--   save(A2_B3_Classifier, A3_B4_Classifier, A2_B3_Regressor, A3_B4_Regressor, A1_B2_Regressor, A1_B2_Classifier, file = "./Results/ALEplotsSim.RData") -->

<!-- } -->
<!-- ``` -->




### Simulating TraitN and Trait Strengths 
#### Small

```{r}
library(TraitMatching)
set.seed(42)
simulation = simulate_batch(numberTraitsA = 7, numberTraitsB = 7, one_way = TRUE, NumberA = 25, NumberB = 50, 
                            cutoff = 0.5, strength_range = c(1,1))

resultR = vector("list",4)

for(i in 1:length(simulation$data)){
  for(n in 1:length(simulation$data[[i]])) {
      resultR[[i]][[n]] = runTM(createCommunity(simulation$data[[i]][[n]]$A, 
                                               simulation$data[[i]][[n]]$B, 
                                               minOneInter(simulation$data[[i]][[n]]$poisson(simulation$res[[i]][[n]])), log = FALSE), 
                           method = c("negBinDnn", "RF", "boost", "knn"), 
            settings = list(negBinDnn = list(seed = 42,  activation = "relu",archFunction = "continous", epochs = 60,distribution = "poisson"),
                            boost = list(objective = "count:poisson")),
                         tune = "random", iters = 50,  fitSpecies = F,
                         crossValidation = list(outer = list(method = "Holdout", split = 4/5, predict = "both"), 
                                                inner = list(method = "Holdout", split = 4/5, predict = "both")), 
                         balanceClasses = "None", block = T, parallel = 50, seed = 42, keepModels = T,tuningMetric = "poisson")
      saveRDS(resultR, file = "./Results/simulationTraitsAndStrengthsRegrWOabSimpleSMALL.RDS")
  }
}

resultC = vector("list", 4)
for(i in 1:length(simulation$data)){
  for(n in 1:length(simulation$data[[i]])) {
      resultC[[i]][[n]] = runTM(createCommunity(simulation$data[[i]][[n]]$A,
                                             simulation$data[[i]][[n]]$B, 
                                             minOneInter(simulation$data[[i]][[n]]$binar(simulation$res[[i]][[n]]))), 
                         method = c("dnn", "RF", "boost", "knn"), 
          settings = list(dnn = list(seed = 42,  activation = "relu",drop = 0.3, archFunction = "continous", epochs = 60)),
                       tune = "random", iters = 50,  fitSpecies = F,
                       crossValidation = list(outer = list(method = "Holdout", split = 4/5, predict = "both"), 
                                              inner = list(method = "Holdout", split = 4/5, predict = "both")), 
                       balanceClasses = "None", block = T, parallel = 50, seed = 42, keepModels = T)
    saveRDS(resultC, file = "./Results/simulationTraitsAndStrengthsClassifWOabSimpleSMALL.RDS")
  }
}


save(simulation, file = "./Results/simulationInterMetaDataSMALL.RData")


```



#### Small Interaction
```{r}
library(TraitMatching)
set.seed(42)
resultRegrWoAb = readRDS(file = "./Results/simulationTraitsAndStrengthsRegrWOabSimpleSMALL.RDS")
sim_len = sapply(resultRegrWoAb, length)
ind_matrix = data.frame(ind1 = rep(1:4,sim_len), ind2 = abind::abind(sapply(1:4, function(i) do.call(seq, list(1, sim_len[i])))))

cl = parallel::makePSOCKcluster(4)
doParallel::registerDoParallel(cl)
.null = parallel::clusterCall(cl, function(x) library(TraitMatching))

system.time({result_reg_small = snow::parSapply(cl = cl,X = 1:nrow(ind_matrix), FUN = function(i, ind_matrix, resultRegrWoAb){
  
  out = vector("list", 4)
  inds = unlist(ind_matrix[i,])
  data = mlr::normalizeFeatures(resultRegrWoAb[[1]][[1]]$classCommunity$data[,-c(1,2)], target = "target")
  
  for(m in 1:4){
    model = resultRegrWoAb[[inds[1]]][[inds[2]]]$Result[[m]]$result$models[[1]]
    out[[m]] = get_Interaction_Strengths(data, model, any = FALSE, depth = 7L,
                              groups = c("A", "B"), grid_size = 500L, 
                              target = "target", parallel = 7L
                               )
    gc()
  }
  gc()
  return(out)
  }, ind_matrix, resultRegrWoAb, simplify = FALSE)

})

saveRDS(result_reg_small, file = "./Results/res_reg_small.RDS")

```


```{r}
library(TraitMatching)
set.seed(42)
resultClassifWoAb = readRDS(file = "./Results/simulationTraitsAndStrengthsClassifWOabSimpleSMALL.RDS")
sim_len = sapply(resultClassifWoAb, length)
ind_matrix = data.frame(ind1 = rep(1:4,sim_len), ind2 = abind::abind(sapply(1:4, function(i) do.call(seq, list(1, sim_len[i])))))

cl = parallel::makePSOCKcluster(4)
doParallel::registerDoParallel(cl)
.null = parallel::clusterCall(cl, function(x) library(TraitMatching))

system.time({result_classif_small = snow::parSapply(cl = cl,X = 1:nrow(ind_matrix), FUN = function(i, ind_matrix, resultClassifWoAb){
  
  out = vector("list", 4)
  inds = unlist(ind_matrix[i,])
  data = mlr::normalizeFeatures(resultClassifWoAb[[1]][[1]]$classCommunity$data[,-c(1,2)], target = "target")
  
  for(m in 1:4){
    model = resultClassifWoAb[[inds[1]]][[inds[2]]]$Result[[m]]$result$models[[1]]
    out[[m]] = get_Interaction_Strengths(data, model, any = FALSE, depth = 7L,
                              groups = c("A", "B"), grid_size = 500L, 
                              target = "target", parallel = 7L
                               )
    gc()
  }
  gc()
  return(out)
  }, ind_matrix, resultClassifWoAb, simplify = FALSE)

})

saveRDS(result_classif_small, file = "./Results/res_classif_small.RDS")

```


#### Middle
```{r}
library(TraitMatching)
set.seed(42)
simulation = simulate_batch(numberTraitsA = 7, numberTraitsB = 7, one_way = TRUE, NumberA = 50, NumberB = 100, cutoff = 0.5, strength_range = c(50,50))



resultR = vector("list",4)

for(i in 1:length(simulation$data)){
  for(n in 1:length(simulation$data[[i]])) {
      resultR[[i]][[n]] = runTM(createCommunity(simulation$data[[i]][[n]]$A, 
                                               simulation$data[[i]][[n]]$B, 
                                               minOneInter(simulation$data[[i]][[n]]$poisson(simulation$res[[i]][[n]])), log = FALSE), 
                           method = c("negBinDnn", "boost"), 
            settings = list(negBinDnn = list(seed = 42,  activation = "relu",archFunction = "continous", epochs = 60,distribution = "poisson"),
                            boost = list(objective = "count:poisson")),
                         tune = "random", iters = 50,  fitSpecies = F,
                         crossValidation = list(outer = list(method = "Holdout", split = 4/5, predict = "both"), 
                                                inner = list(method = "Holdout", split = 4/5, predict = "both")), 
                         balanceClasses = "None", block = T, parallel = 50, seed = 42, keepModels = T,tuningMetric = "poisson")
      saveRDS(resultR, file = "./Results/simulationTraitsAndStrengthsRegrWOabSimpleMIDDLE.RDS")
  }
}

resultC = vector("list", 4)
for(i in 1:length(simulation$data)){
  for(n in 1:length(simulation$data[[i]])) {
      resultC[[i]][[n]] = runTM(createCommunity(simulation$data[[i]][[n]]$A,
                                             simulation$data[[i]][[n]]$B, 
                                             minOneInter(simulation$data[[i]][[n]]$binar(simulation$res[[i]][[n]]))), 
                         method = c("dnn",  "boost"), 
          settings = list(dnn = list(seed = 42,  activation = "relu",drop = 0.3, archFunction = "continous", epochs = 60)),
                       tune = "random", iters = 50,  fitSpecies = F,
                       crossValidation = list(outer = list(method = "Holdout", split = 4/5, predict = "both"), 
                                              inner = list(method = "Holdout", split = 4/5, predict = "both")), 
                       balanceClasses = "None", block = T, parallel = 50, seed = 42, keepModels = T)
    saveRDS(resultC, file = "./Results/simulationTraitsAndStrengthsClassifWOabSimpleMIDDLE.RDS")
  }
}





save(simulation, file = "./Results/simulationInterMetaDataSMIDDLE.RData")


```


#### Middle Interaction
```{r}
library(TraitMatching)
set.seed(42)
resultRegrWoAb = readRDS(file = "./Results/simulationTraitsAndStrengthsRegrWOabSimpleMIDDLE.RDS")
sim_len = sapply(resultRegrWoAb, length)
ind_matrix = data.frame(ind1 = rep(1:4,sim_len), ind2 = abind::abind(sapply(1:4, function(i) do.call(seq, list(1, sim_len[i])), simplify = F) ))

cl = parallel::makePSOCKcluster(3)
doParallel::registerDoParallel(cl)
.null = parallel::clusterCall(cl, function(x) library(TraitMatching))

system.time({result_reg_small = snow::parSapply(cl = cl,X = 1:nrow(ind_matrix), FUN = function(i, ind_matrix, resultRegrWoAb){
  
  out = vector("list", 4)
  inds = unlist(ind_matrix[i,])
  data = mlr::normalizeFeatures(resultRegrWoAb[[1]][[1]]$classCommunity$data[,-c(1,2)], target = "target")
  
  for(m in 1:2){
    model = resultRegrWoAb[[inds[1]]][[inds[2]]]$Result[[m]]$result$models[[1]]
    print(model)
    out[[m]] = get_Interaction_Strengths(data, model, any = FALSE, depth = 7L,
                              groups = c("A", "B"), grid_size = 500L, 
                              target = "target", parallel = 3L
                               )
    gc()
  }
  gc()
  return(out)
  }, ind_matrix, resultRegrWoAb, simplify = FALSE)

})

saveRDS(result_reg_small, file = "./Results/res_reg_middle.RDS")

```

```{r}
library(TraitMatching)
set.seed(42)
resultClassifWoAb = readRDS(file = "./Results/simulationTraitsAndStrengthsClassifWOabSimpleMIDDLE.RDS")
sim_len = sapply(resultClassifWoAb, length)
ind_matrix = data.frame(ind1 = rep(1:4,sim_len), ind2 = abind::abind(sapply(1:4, function(i) do.call(seq, list(1, sim_len[i])),simplify = F)))

cl = parallel::makePSOCKcluster(2)
doParallel::registerDoParallel(cl)
.null = parallel::clusterCall(cl, function(x) library(TraitMatching))

system.time({result_classif_middle = snow::parSapply(cl = cl,X = 1:nrow(ind_matrix), FUN = function(i, ind_matrix, resultClassifWoAb){
  
  out = vector("list", 4)
  inds = unlist(ind_matrix[i,])
  data = mlr::normalizeFeatures(resultClassifWoAb[[1]][[1]]$classCommunity$data[,-c(1,2)], target = "target")
  
  for(m in 1:2){
    model = resultClassifWoAb[[inds[1]]][[inds[2]]]$Result[[m]]$result$models[[1]]
    out[[m]] = get_Interaction_Strengths(data, model, any = FALSE, depth = 7L,
                              groups = c("A", "B"), grid_size = 500L, 
                              target = "target", parallel = 3L
                               )
    gc()
  }
  gc()
  return(out)
  }, ind_matrix, resultClassifWoAb, simplify = FALSE)

})

saveRDS(result_classif_middle, file = "./Results/res_classif_middle.RDS")

```

### Results
#### Small
```{r}
regrRes = readRDS(file = "./Results/res_reg_small.RDS")
classRes = readRDS(file = "./Results/res_classif_small.RDS")

studyResReg = readRDS(file = './Results/simulationTraitsAndStrengthsRegrWOabSimpleSMALL.RDS')
studyClassReg = readRDS(file = './Results/simulationTraitsAndStrengthsClassifWOabSimpleSMALL.RDS')

load(file = './Results/simulationInterMetaDataResultSMALL.RData')

library(TraitMatching)

TraitInter = simulation$TraitInter

TraitInter = lapply(1:4, function(i){
  ind = matrix(1:ncol(TraitInter[[i]]), ncol = 2,byrow = T)
  out = matrix("", nrow = 10, ncol = ncol(TraitInter[[i]])*0.5)
  for(j in 1:nrow(ind)) {
    out[,j] = apply(TraitInter[[i]][,ind[j,]], 1, function(x) paste0(x[1], ":", x[2]))
  }
  return(out)
})


# update metda:
TraitInter = lapply(1:4, function(i) {
  lapply(1:10, function(j) if(simulation$survived_interactions[[i]][j] >= 0.5*25*50) return(TraitInter[[i]][j,]) else return(NULL))
})

TraitStrengths = lapply(1:4, function(i) {
  lapply(1:10, function(j) if(simulation$survived_interactions[[i]][j] >= 0.5*25*50) return(simulation$TraitStrengths[[i]][j,]) else return(NULL))
})

for(i in 1:4){
  TraitStrengths[[i]][sapply(TraitStrengths[[i]], is.null)] <- NULL
  TraitInter[[i]][sapply(TraitInter[[i]], is.null)] <- NULL
}

aggResRegr = aggregate_interaction_result(model_result = studyResReg, inter_results = regrRes,trait_inter = TraitInter, trait_strengths = TraitStrengths)

aggResClass = aggregate_interaction_result(model_result = studyClassReg, inter_results = classRes,trait_inter = TraitInter, trait_strengths = TraitStrengths)

sim_len = sapply(studyResReg, length)
ind_matrix = data.frame(ind1 = rep(1:4,sim_len), ind2 = abind::abind(sapply(1:4, function(i) do.call(seq, list(1, sim_len[i])), simplify = F) ))

aggResRegr$repetition = rep(unlist(apply(ind_matrix, 1, function(x) rep(x[2], x[1]))), rep(4, length(unlist(apply(ind_matrix, 1, function(x) rep(x[2], x[1]))))))
aggResClass$repetition = rep(unlist(apply(ind_matrix, 1, function(x) rep(x[2], x[1]))), rep(4, length(unlist(apply(ind_matrix, 1, function(x) rep(x[2], x[1]))))))


resAggSmallReg = aggTrpRep(aggTrp(aggResRegr), aggResRegr)
resAggSmallClass = aggTrpRep(aggTrp(aggResClass), aggResClass)

```

#### Middle
```{r}

regrRes = readRDS(file = "./Results/res_reg_middle.RDS")
classRes = readRDS(file = "./Results/res_classif_middle.RDS")

studyResReg = readRDS(file = './Results/simulationTraitsAndStrengthsRegrWOabSimpleMIDDLE.RDS')
studyClassReg = readRDS(file = './Results/simulationTraitsAndStrengthsClassifWOabSimpleMIDDLE.RDS')

load(file = './Results/simulationInterMetaDataSMIDDLE.RData')

library(TraitMatching)

TraitInter = simulation$TraitInter

TraitInter = lapply(1:4, function(i){
  ind = matrix(1:ncol(TraitInter[[i]]), ncol = 2,byrow = T)
  out = matrix("", nrow = 10, ncol = ncol(TraitInter[[i]])*0.5)
  for(j in 1:nrow(ind)) {
    out[,j] = apply(TraitInter[[i]][,ind[j,]], 1, function(x) paste0(x[1], ":", x[2]))
  }
  return(out)
})


# update metda:
TraitInter = lapply(1:4, function(i) {
  lapply(1:10, function(j) if(simulation$survived_interactions[[i]][j] >= 0.5*25*50) return(TraitInter[[i]][j,]) else return(NULL))
})

TraitStrengths = lapply(1:4, function(i) {
  lapply(1:10, function(j) if(simulation$survived_interactions[[i]][j] >= 0.5*25*50) return(simulation$TraitStrengths[[i]][j,]) else return(NULL))
})

for(i in 1:4){
  TraitStrengths[[i]][sapply(TraitStrengths[[i]], is.null)] <- NULL
  TraitInter[[i]][sapply(TraitInter[[i]], is.null)] <- NULL
}


aggResRegr = aggregate_interaction_result(model_result = studyResReg, inter_results = regrRes,trait_inter = TraitInter, trait_strengths = TraitStrengths)

aggResClass = aggregate_interaction_result(model_result = studyClassReg, inter_results = classRes,trait_inter = TraitInter, trait_strengths = TraitStrengths)

aggResRegr$repetition = rep(unlist(apply(ind_matrix, 1, function(x) rep(x[2], x[1]))), rep(2, length(unlist(apply(ind_matrix, 1, function(x) rep(x[2], x[1]))))))
aggResClass$repetition = rep(unlist(apply(ind_matrix, 1, function(x) rep(x[2], x[1]))), rep(2, length(unlist(apply(ind_matrix, 1, function(x) rep(x[2], x[1]))))))

resAggMiddleReg = aggTrpRep(aggTrp(aggResRegr), aggResRegr)
resAggMiddleClass = aggTrpRep(aggTrp(aggResClass), aggResClass)
```


#### Figure
```{r}

pdf(file = "./Figures/Fig4.pdf",width = 5.5,height = 3.5)
par(mfrow = c(1,2), mar = c(1,2,0.6,0.1)+0.1,oma = c(0.0,0.2,1.2,0.1))
plotResAgg(resAggSmallReg)
text(xpd = NA, x = -0.1, y = 1.1, labels = "a)", font = 2)
plotResAgg(resAggSmallClass)
text(xpd = NA, x = -0.1, y = 1.1, labels = "b)", font = 2)
dev.off()

plotResAgg(resAggMiddleReg,labels = c("DNN", "BRT"))
text(xpd = NA, x = -0.1, y = 1.1, labels = "c)", font = 2)
plotResAgg(resAggMiddleClass,labels = c("DNN", "BRT"))
text(xpd = NA, x = -0.1, y = 1.1, labels = "d)", font = 2)
dev.off()

```





# Hummingbird-plant network


```{r,results=FALSE}

inH = read.csv("./PlantBird/interact_matrix_high.csv")
inM = read.csv("./PlantBird/interact_matrix_mid.csv")
inL = read.csv("./PlantBird/interact_matrix_low.csv")

tbH = read.csv("./PlantBird/traitbird_high.csv",col.names = c("Hummingbird", "Bill.Length", "Bill.Curvature", "Body.Mass", "Wing", "Tail")) %>% normalizeFeatures(method = "center")
tbM = read.csv("./PlantBird/traitbird_mid.csv",col.names = c("Hummingbird", "Bill.Length", "Bill.Curvature", "Body.Mass", "Wing", "Tail")) %>% normalizeFeatures(method = "center")
tbL = read.csv("./PlantBird/traitbird_low.csv",col.names = c("Hummingbird", "Bill.Length", "Bill.Curvature", "Body.Mass", "Wing", "Tail")) %>% normalizeFeatures(method = "center")

tpH = read.csv("./PlantBird/traitplant_high.csv", col.names = c("Plant", "Corolla.Length", "Corolla.Curvature", "Corolla.Volumen", "Inner.Diameter", "Ext.Diameter", "NumIndividuals")) %>% normalizeFeatures(method = "center", cols = c("Corolla.Length", "Corolla.Curvature", "Corolla.Volumen", "Inner.Diameter", "Ext.Diameter"))
tpM = read.csv("./PlantBird/traitplant_mid.csv", col.names = c("Plant", "Corolla.Length", "Corolla.Curvature", "Corolla.Volumen", "Inner.Diameter", "Ext.Diameter", "NumIndividuals")) %>% normalizeFeatures(method = "center", cols = c("Corolla.Length", "Corolla.Curvature", "Corolla.Volumen", "Inner.Diameter", "Ext.Diameter"))
tpL = read.csv("./PlantBird/traitplant_low.csv", col.names = c("Plant", "Corolla.Length", "Corolla.Curvature", "Corolla.Volumen", "Inner.Diameter", "Ext.Diameter", "NumIndividuals")) %>% normalizeFeatures(method = "center", cols = c("Corolla.Length", "Corolla.Curvature", "Corolla.Volumen", "Inner.Diameter", "Ext.Diameter"))


rownames(inH) = as.character(inH$X)
inH = inH[,-1]
rownames(inM) = as.character(inM$X)
inM = inM[,-1]
rownames(inL) = as.character(inL$X)
inL = inL[,-1]


```





### Train models
Create combinations of networks and fit learner in 60 tuning steps with three-fold cross-validation

```{r,results=FALSE}
if(run){
  tbH_c = tbH
  tbM_c = tbM
  tbL_c = tbL
  tbH_c$plot = as.factor(rep("High", nrow(tbH)))
  tbM_c$plot = as.factor(rep("Mid", nrow(tbM)))
  tbL_c$plot = as.factor(rep("Low", nrow(tbL)))
  
  communityCombined =  createCommunity(community = list(list(tpH, tbH_c, inH), list(tpM, tbM_c, inM), list(tpL, tbL_c, inL)),log = F)
  communityCombined$data = communityCombined$data %>% mutate(target = target/NumIndividuals) %>% 
    select(-NumIndividuals) %>% createDummyFeatures(cols = "plot") 
  
  
  Low = LowMid = LowHigh = MidHigh = High = Mid = all =  communityCombined
  Low$data = communityCombined$data[communityCombined$data$plot.Low > 0 ,1:13 ] %>% normalizeFeatures(target = "target")
  Low$block = communityCombined$block[communityCombined$data$plot.Low > 0 ,]
  
  LowMid$data = communityCombined$data[communityCombined$data$plot.Low > 0 | communityCombined$data$plot.Mid > 0,c(1:13)] %>% normalizeFeatures(target = "target")
  LowMid$block = communityCombined$block[communityCombined$data$plot.Low > 0 | communityCombined$data$plot.Mid > 0,]
  
  LowHigh$data = communityCombined$data[communityCombined$data$plot.Low > 0 | communityCombined$data$plot.High > 0,c(1:13)] %>% normalizeFeatures(target = "target")
  LowHigh$block = communityCombined$block[communityCombined$data$plot.Low > 0 | communityCombined$data$plot.High > 0,]
  
  MidHigh$data = communityCombined$data[communityCombined$data$plot.Mid > 0 | communityCombined$data$plot.High > 0,c(1:13)] %>% normalizeFeatures(target = "target")
  MidHigh$block = communityCombined$block[communityCombined$data$plot.Mid > 0 | communityCombined$data$plot.High > 0,]
  
  High$data = communityCombined$data[communityCombined$data$plot.High > 0 ,1:13 ] %>% normalizeFeatures(target = "target")
  High$block = communityCombined$block[communityCombined$data$plot.High > 0 ,]
  
  Mid$data = communityCombined$data[communityCombined$data$plot.Mid > 0 ,1:13 ] %>% normalizeFeatures(target = "target")
  Mid$block = communityCombined$block[communityCombined$data$plot.Mid > 0 ,]
  
  all$data = communityCombined$data %>% normalizeFeatures(target = "target")
  all$block = communityCombined$block[,]
  
  community = list(Low = Low,
                   Mid = Mid,
                   High = High,
                   MidHigh = MidHigh,
                   LowMid = LowMid,
                   LowHigh = LowHigh,
                   all = all
                   )
  
  # two DNN: Poisson and negative binomial distributions
  
  learnerNegBinDnn = makeLearner("regr.negBinDnn",seed = 42, batch = 25,archFunction = "continous", distribution = "negBin", epochs = 60)
  learnerPoissonDnn = makeLearner("regr.negBinDnn",seed = 42, batch = 25,archFunction = "continous", distribution = "poisson", epochs = 60)
  learnerRF = makeLearner("regr.randomForest", predict.type = "se")
  learnerBoost = makeLearner("regr.xgboost", objective = "count:poisson")
  parDnn = makeParamSet(makeNumericParam("lr", lower = 0.0001, upper = 0.01),
                        makeIntegerParam("arch", lower = 5L, upper = 35L),
                        makeIntegerParam("nLayer", 1, 5),
                        makeLogicalParam("bias", default = T)
                        )
  
  parRF = makeParamSet(makeIntegerParam("mtry",lower = 2,upper = 10),         
                        makeIntegerParam("nodesize",lower = 2,upper = 50))
  parBoost <- makeParamSet(makeDiscreteParam("booster", values = c("gbtree", "dart")),
                          makeDiscreteParam("sample_type", values = c("uniform", "weighted"), requires = quote(booster == "dart")),
                          makeDiscreteParam("normalize_type", values = c("tree", "forest"), requires = quote(booster == "dart")),
                          makeNumericParam("eta", lower = 0.01, upper = 0.5),
                          makeNumericParam("gamma", lower = -9, upper = 5, trafo = function(x) 2^x),
                          makeIntegerParam("max_depth", lower = 1, upper = 10),
                          makeNumericParam("lambda", lower = -1, upper = 0, trafo = function(x) 10^x),
                          makeNumericParam("alpha", lower = -10, upper = 5, trafo = function(x) 2^x),
                          makeNumericParam("min_child_weight", 0, 10),
                          makeIntegerParam("nrounds", lower = 20, upper = 300),
                          makeNumericParam("rate_drop", lower = 0, upper = 0.2, requires = quote(booster == "dart")),
                          makeNumericParam("skip_drop", lower = 0, upper = 0.3, requires = quote(booster == "dart")))
  
  
  
  modelNegBin = vector("list", 7)
  modelRF = vector("list", 7)
  modelPoisson= vector("list", 7)
  modelBoost = vector("list",7)
  parallelMap::parallelStartSocket(cpus = 30, level = "mlr.tuneParams")
  predictLearner.regr.negBinDnn = TraitMatching:::predictLearner.regr.negBinDnn
  trainLearner.regr.negBinDnn = TraitMatching:::trainLearner.regr.negBinDnn
  parallelMap::parallelExport("trainLearner.regr.negBinDnn", "predictLearner.regr.negBinDnn", level = "mlr.tuneParams")
  
  
  
  for(i in 1:7){
   set.seed(42)
    task = makeRegrTask(data = community[[i]]$data[,-c(1,2)], target = "target", coordinates = community[[i]]$block)
    
    modelNegBin[[i]] = mlr::train(setHyperPars(learnerNegBinDnn,par.vals =  tuneParams(learnerNegBinDnn, par.set = parDnn,
                                                               control = makeTuneControlRandom(maxit = 60),measures = spearmanrho,show.info = T,
                                                              task = task, resampling = makeResampleDesc("SpCV", iters = 3))$x)
                              ,task = task)
  
    modelPoisson[[i]] = mlr::train(setHyperPars(learnerPoissonDnn,par.vals =  tuneParams(learnerNegBinDnn, par.set = parDnn,
                                                               control = makeTuneControlRandom(maxit = 60),measures = spearmanrho,show.info = T,
                                                              task = task, resampling = makeResampleDesc("SpCV", iters = 3))$x)
                              ,task = task)
    
    modelRF[[i]] = mlr::train(setHyperPars(learnerRF,par.vals =  tuneParams(learnerRF, par.set = parRF,
                                                              control = makeTuneControlRandom(maxit = 60),measures = spearmanrho,show.info = T,
                                                              task = task, resampling = makeResampleDesc("SpCV", iters = 3))$x)
                              ,task = task)
    modelBoost[[i]] = mlr::train(setHyperPars(learnerBoost,par.vals =  tuneParams(learnerBoost, par.set = parBoost,
                                                              control = makeTuneControlRandom(maxit = 60),measures = spearmanrho,show.info = T,
                                                              task = task, resampling = makeResampleDesc("SpCV", iters = 3))$x)
                              ,task = task)
  
  
  }
  names(modelNegBin) = names(community)
  names(modelPoisson) = names(community)
  names(modelRF) = names(community)
  names(modelBoost) = names(community)
  
  save(modelRF, modelBoost, modelNegBin, modelPoisson, community, file = "./Results/HummingBirdResult.RData")
}


```


```{r,results=FALSE}
load(file = "./Results/HummingBirdResult.RData")
```

### Compute overall+pairwise interaction strengths


```{r,results=FALSE}
if(run){
  set.seed(42)
  models = list(boost = modelBoost, negbin = modelNegBin, poisson = modelPoisson, rf = modelRF)
  
  
  ResultInterLow = list()
  for(i in names(models)){
      cat(i)
      ResultInterLow[[i]] = 
        get_Interaction_Strengths(data = community$Low$data[,-c(1,2)], model = models[[i]][["Low"]], any = FALSE, depth = 10L,
                              groups = NULL, grid_size = nrow(community$Low$data[,-c(1,2)]), 
                              target = "target", parallel = 10L
                               )
  }
  
  ResultInterMid= list()
  for(i in names(models)){
      cat(i)
    ResultInterMid[[i]] =
      get_Interaction_Strengths(data = community$Mid$data[,-c(1,2)], model = models[[i]][["Mid"]], any = FALSE, depth = 10L,
                              groups = NULL, grid_size = nrow(community$Mid$data[,-c(1,2)]), 
                              target = "target", parallel = 10L
                               )
    gc()
  }
  
  ResultInterHigh = list()
  for(i in names(models)){
      cat(i)
    ResultInterHigh[[i]]=
      get_Interaction_Strengths(data = community$High$data[,-c(1,2)], model = models[[i]][["High"]], any = FALSE, depth = 10L,
                              groups = NULL, grid_size = nrow(community$High$data[,-c(1,2)]), 
                              target = "target", parallel = 10L
                               )
    gc()
  }
  
  ResultInterCombined = list()
  for(i in names(models)){
      cat(i)
    ResultInterCombined[[i]] =
      get_Interaction_Strengths(data = community$all$data[,-c(1,2)], model = models[[i]][["all"]], any = FALSE, depth = 13L,
                              groups = NULL, grid_size = nrow(community$all$data[,-c(1,2)]), 
                              target = "target", parallel = 13L
                               )
    gc()
  }
  
  save(ResultInterLow,ResultInterMid,ResultInterHigh,ResultInterCombined, file = "./Results/HummingInferenceResult.RData")
}

```


